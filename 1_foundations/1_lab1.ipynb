{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the start of your adventure in Agentic AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Are you ready for action??</h2>\n",
    "            <span style=\"color:#ff7800;\">Have you completed all the setup steps in the <a href=\"../setup/\">setup</a> folder?<br/>\n",
    "            Have you read the <a href=\"../README.md\">README</a>? Many common questions are answered here!<br/>\n",
    "            Have you checked out the guides in the <a href=\"../guides/01_intro.ipynb\">guides</a> folder?<br/>\n",
    "            Well in that case, you're ready!!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">This code is a live resource - keep an eye out for my updates</h2>\n",
    "            <span style=\"color:#00bfff;\">I push updates regularly. As people ask questions or have problems, I add more examples and improve explanations. As a result, the code below might not be identical to the videos, as I've added more steps and better comments. Consider this like an interactive book that accompanies the lectures.<br/><br/>\n",
    "            I try to send emails regularly with important updates related to the course. You can find this in the 'Announcements' section of Udemy in the left sidebar. You can also choose to receive my emails via your Notification Settings in Udemy. I'm respectful of your inbox and always try to add value with my emails!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And please do remember to contact me if I can help\n",
    "\n",
    "And I love to connect: https://www.linkedin.com/in/eddonner/\n",
    "\n",
    "\n",
    "### New to Notebooks like this one? Head over to the guides folder!\n",
    "\n",
    "Just to check you've already added the Python and Jupyter extensions to Cursor, if not already installed:\n",
    "- Open extensions (View >> extensions)\n",
    "- Search for python, and when the results show, click on the ms-python one, and Install it if not already installed\n",
    "- Search for jupyter, and when the results show, click on the Microsoft one, and Install it if not already installed  \n",
    "Then View >> Explorer to bring back the File Explorer.\n",
    "\n",
    "And then:\n",
    "1. Click where it says \"Select Kernel\" near the top right, and select the option called `.venv (Python 3.12.9)` or similar, which should be the first choice or the most prominent choice. You may need to choose \"Python Environments\" first.\n",
    "2. Click in each \"cell\" below, starting with the cell immediately below this text, and press Shift+Enter to run\n",
    "3. Enjoy!\n",
    "\n",
    "After you click \"Select Kernel\", if there is no option like `.venv (Python 3.12.9)` then please do the following:  \n",
    "1. On Mac: From the Cursor menu, choose Settings >> VS Code Settings (NOTE: be sure to select `VSCode Settings` not `Cursor Settings`);  \n",
    "On Windows PC: From the File menu, choose Preferences >> VS Code Settings(NOTE: be sure to select `VSCode Settings` not `Cursor Settings`)  \n",
    "2. In the Settings search bar, type \"venv\"  \n",
    "3. In the field \"Path to folder with a list of Virtual Environments\" put the path to the project root, like C:\\Users\\username\\projects\\agents (on a Windows PC) or /Users/username/projects/agents (on Mac or Linux).  \n",
    "And then try again.\n",
    "\n",
    "Having problems with missing Python versions in that list? Have you ever used Anaconda before? It might be interferring. Quit Cursor, bring up a new command line, and make sure that your Anaconda environment is deactivated:    \n",
    "`conda deactivate`  \n",
    "And if you still have any problems with conda and python versions, it's possible that you will need to run this too:  \n",
    "`conda config --set auto_activate_base false`  \n",
    "and then from within the Agents directory, you should be able to run `uv python list` and see the Python 3.12 version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's do an import. If you get an Import Error, double check that your Kernel is correct..\n",
    "\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next it's time to load the API keys into environment variables\n",
    "# If this returns false, see the next cell!\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait, did that just output `False`??\n",
    "\n",
    "If so, the most common reason is that you didn't save your `.env` file after adding the key! Be sure to have saved.\n",
    "\n",
    "Also, make sure the `.env` file is named precisely `.env` and is in the project root directory (`agents`)\n",
    "\n",
    "By the way, your `.env` file should have a stop symbol next to it in Cursor on the left, and that's actually a good thing: that's Cursor saying to you, \"hey, I realize this is a file filled with secret information, and I'm not going to send it to an external AI to suggest changes, because your keys should not be shown to anyone else.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Final reminders</h2>\n",
    "            <span style=\"color:#ff7800;\">1. If you're not confident about Environment Variables or Web Endpoints / APIs, please read Topics 3 and 5 in this <a href=\"../guides/04_technical_foundations.ipynb\">technical foundations guide</a>.<br/>\n",
    "            2. If you want to use AIs other than OpenAI, like Gemini, DeepSeek or Ollama (free), please see the first section in this <a href=\"../guides/09_ai_apis_and_ollama.ipynb\">AI APIs guide</a>.<br/>\n",
    "            3. If you ever get a Name Error in Python, you can always fix it immediately; see the last section of this <a href=\"../guides/06_python_foundations.ipynb\">Python Foundations guide</a> and follow both tutorials and exercises.<br/>\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n"
     ]
    }
   ],
   "source": [
    "# Check the key - if you're not using OpenAI, check whichever key you're using! Ollama doesn't need a key.\n",
    "\n",
    "import os\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set - please head to the troubleshooting guide in the setup folder\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - the all important import statement\n",
    "# If you get an import error - head over to troubleshooting in the Setup folder\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now we'll create an instance of the OpenAI class\n",
    "# If you're not sure what it means to create an instance of a class - head over to the guides folder (guide 6)!\n",
    "# If you get a NameError - head over to the guides folder (guide 6)to learn about NameErrors - always instantly fixable\n",
    "# If you're not using OpenAI, you just need to slightly modify this - precise instructions are in the AI APIs guide (guide 9)\n",
    "\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of messages in the familiar OpenAI format\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"What is 2+2?\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 + 2 equals 4.\n"
     ]
    }
   ],
   "source": [
    "# And now call it! Any problems, head to the troubleshooting guide\n",
    "# This uses GPT 4.1 nano, the incredibly cheap model\n",
    "# The APIs guide (guide 9) has exact instructions for using even cheaper or free alternatives to OpenAI\n",
    "# If you get a NameError, head to the guides folder (guide 6) to learn about NameErrors - always instantly fixable\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-nano\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now - let's ask for a question:\n",
    "\n",
    "question = \"Please propose a hard, challenging question to assess someone's IQ. Respond only with the question.\"\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If three people can paint three walls in three hours, how long will it take five people to paint five walls? Explain your reasoning.\n"
     ]
    }
   ],
   "source": [
    "# ask it - this uses GPT 4.1 mini, still cheap but more powerful than nano\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "question = response.choices[0].message.content\n",
    "\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form a new messages list\n",
    "messages = [{\"role\": \"user\", \"content\": question}]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's analyze the problem step-by-step.\n",
      "\n",
      "### Given:\n",
      "- 3 people can paint 3 walls in 3 hours.\n",
      "\n",
      "### Goal:\n",
      "- How long will it take 5 people to paint 5 walls?\n",
      "\n",
      "---\n",
      "\n",
      "### Step 1: Find the painting rate per person\n",
      "\n",
      "If 3 people paint 3 walls in 3 hours, the total **person-hours** spent is:\n",
      "\n",
      "\\[\n",
      "3 \\text{ people} \\times 3 \\text{ hours} = 9 \\text{ person-hours}\n",
      "\\]\n",
      "\n",
      "This 9 person-hours results in painting 3 walls, so the time to paint one wall in person-hours is:\n",
      "\n",
      "\\[\n",
      "\\frac{9 \\text{ person-hours}}{3 \\text{ walls}} = 3 \\text{ person-hours per wall}\n",
      "\\]\n",
      "\n",
      "This means **it takes one person 3 hours to paint one wall.**\n",
      "\n",
      "---\n",
      "\n",
      "### Step 2: Calculate total person-hours for 5 walls\n",
      "\n",
      "If one wall requires 3 person-hours, 5 walls will require:\n",
      "\n",
      "\\[\n",
      "5 \\text{ walls} \\times 3 \\text{ person-hours per wall} = 15 \\text{ person-hours}\n",
      "\\]\n",
      "\n",
      "---\n",
      "\n",
      "### Step 3: Find the time 5 people take to paint 5 walls\n",
      "\n",
      "Since 5 people work together, the number of hours required is:\n",
      "\n",
      "\\[\n",
      "\\frac{15 \\text{ person-hours}}{5 \\text{ people}} = 3 \\text{ hours}\n",
      "\\]\n",
      "\n",
      "---\n",
      "\n",
      "### **Answer:**\n",
      "\n",
      "It will take **5 people 3 hours** to paint 5 walls.\n",
      "\n",
      "---\n",
      "\n",
      "### **Explanation:**\n",
      "\n",
      "The rate of painting is proportional to the number of people and the number of walls—doubling both keeps the time constant. Since each wall takes 3 person-hours to paint and more people share the work, the time remains the same when walls and people increase proportionally.\n"
     ]
    }
   ],
   "source": [
    "# Ask it again\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "answer = response.choices[0].message.content\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Let's analyze the problem step-by-step.\n",
       "\n",
       "### Given:\n",
       "- 3 people can paint 3 walls in 3 hours.\n",
       "\n",
       "### Goal:\n",
       "- How long will it take 5 people to paint 5 walls?\n",
       "\n",
       "---\n",
       "\n",
       "### Step 1: Find the painting rate per person\n",
       "\n",
       "If 3 people paint 3 walls in 3 hours, the total **person-hours** spent is:\n",
       "\n",
       "\\[\n",
       "3 \\text{ people} \\times 3 \\text{ hours} = 9 \\text{ person-hours}\n",
       "\\]\n",
       "\n",
       "This 9 person-hours results in painting 3 walls, so the time to paint one wall in person-hours is:\n",
       "\n",
       "\\[\n",
       "\\frac{9 \\text{ person-hours}}{3 \\text{ walls}} = 3 \\text{ person-hours per wall}\n",
       "\\]\n",
       "\n",
       "This means **it takes one person 3 hours to paint one wall.**\n",
       "\n",
       "---\n",
       "\n",
       "### Step 2: Calculate total person-hours for 5 walls\n",
       "\n",
       "If one wall requires 3 person-hours, 5 walls will require:\n",
       "\n",
       "\\[\n",
       "5 \\text{ walls} \\times 3 \\text{ person-hours per wall} = 15 \\text{ person-hours}\n",
       "\\]\n",
       "\n",
       "---\n",
       "\n",
       "### Step 3: Find the time 5 people take to paint 5 walls\n",
       "\n",
       "Since 5 people work together, the number of hours required is:\n",
       "\n",
       "\\[\n",
       "\\frac{15 \\text{ person-hours}}{5 \\text{ people}} = 3 \\text{ hours}\n",
       "\\]\n",
       "\n",
       "---\n",
       "\n",
       "### **Answer:**\n",
       "\n",
       "It will take **5 people 3 hours** to paint 5 walls.\n",
       "\n",
       "---\n",
       "\n",
       "### **Explanation:**\n",
       "\n",
       "The rate of painting is proportional to the number of people and the number of walls—doubling both keeps the time constant. Since each wall takes 3 person-hours to paint and more people share the work, the time remains the same when walls and people increase proportionally."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(answer))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations!\n",
    "\n",
    "That was a small, simple step in the direction of Agentic AI, with your new environment!\n",
    "\n",
    "Next time things get more interesting..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Now try this commercial application:<br/>\n",
    "            First ask the LLM to pick a business area that might be worth exploring for an Agentic AI opportunity.<br/>\n",
    "            Then ask the LLM to present a pain-point in that industry - something challenging that might be ripe for an Agentic solution.<br/>\n",
    "            Finally have 3 third LLM call propose the Agentic AI solution. <br/>\n",
    "            We will cover this at up-coming labs, so don't worry if you're unsure.. just give it a try!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create the messages:\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": \"Something here\"}]\n",
    "\n",
    "# Then make the first call:\n",
    "\n",
    "response =\n",
    "\n",
    "# Then read the business idea:\n",
    "\n",
    "business_idea = response.\n",
    "\n",
    "# And repeat! In the next message, include the business idea within the message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Opportunity Identification:**\n",
      "\n",
      "In Mexico, there is a growing interest in church planting and biblical training, especially in underserved or rural regions where access to formal theological education is limited. A Christian non-profit organization specializing in **Biblical and church-planting training** could leverage digital tools to expand their reach, provide contextualized theological resources, and support local leaders who might have limited formal training but a strong calling.\n",
      "\n",
      "---\n",
      "\n",
      "### Opportunity:\n",
      "**Developing a localized, AI-powered virtual coaching assistant for church planters and biblical trainees.**\n",
      "\n",
      "---\n",
      "\n",
      "### Scenario for Agentic AI Integration:\n",
      "\n",
      "**Virtual Coaching and Personalized Learning for Church Planters**\n",
      "\n",
      "- **Description:**  \n",
      "  An AI-powered virtual assistant could provide personalized training pathways, scriptural insights, ministry leadership tips, and strategic guidance to church planters in Mexico. This assistant could simulate a knowledgeable mentor that offers contextualized advice based on local culture, language, and ministry challenges. For example:\n",
      "  - Providing biblical exegesis tailored to Latin American cultural contexts.\n",
      "  - Offering church planting strategies suited for rural Mexico.\n",
      "  - Helping trainees practice sermon delivery or Q&A sessions.\n",
      "  - Facilitating community-building by connecting trainees with peers and mentors.\n",
      "\n",
      "- **Agentic AI Role:**  \n",
      "  The AI would act autonomously in guiding learners along customized learning paths, assessing progress, and adapting content dynamically. It could answer questions instantly, provide theological resources, and encourage practical implementation ideas, enhancing the scalability and impact of the organization’s training programs.\n",
      "\n",
      "---\n",
      "\n",
      "### Possible Limitations or Challenges in Accessing AI and LLM Tools from Mexico:\n",
      "\n",
      "1. **Internet Connectivity:**  \n",
      "   Many rural areas in Mexico have limited or unreliable internet access, which can hinder the use of cloud-based AI services that require real-time interaction.\n",
      "\n",
      "2. **Cost and Infrastructure:**  \n",
      "   Access to large language models (LLMs) and advanced AI tools can be expensive. The non-profit may lack budget or infrastructure to deploy and maintain these technologies on-premises and might rely on subscription models or cloud providers.\n",
      "\n",
      "3. **Language and Localization:**  \n",
      "   While Spanish-language models exist, many LLMs perform better in English. There may be gaps in accurately understanding and generating culturally relevant, theologically sound content in Mexican Spanish.\n",
      "\n",
      "4. **Data Privacy and Regulatory Issues:**  \n",
      "   Mexican laws around data protection (e.g., the Federal Law on Protection of Personal Data Held by Private Parties - LFPDPPP) must be adhered to, especially when dealing with personal data from learners or church planters.\n",
      "\n",
      "5. **Digital Literacy:**  \n",
      "   Trainees and local church planters might have varying levels of comfort and familiarity with technology, requiring user-friendly interfaces and training on how to use AI tools effectively.\n",
      "\n",
      "6. **Ethical and Theological Oversight:**  \n",
      "   AI-generated theological content must be carefully reviewed by human experts to ensure doctrinal accuracy and prevent misinformation or theological errors.\n",
      "\n",
      "---\n",
      "\n",
      "### Summary:\n",
      "\n",
      "A Christian non-profit focused on biblical and church-planting training in Mexico can greatly benefit from an agentic AI-driven virtual coaching system that personalizes training and mentorship at scale. Addressing challenges like connectivity, cost, localization, legal compliance, and digital literacy will be key to sustainably implementing such AI-enhanced solutions in the Mexican context.\n"
     ]
    }
   ],
   "source": [
    "# pick a sector that may benefit from Agentic AI\n",
    "\n",
    "content = \"\"\"\n",
    "Identify an opportunity in the Christian non-profit sector that specializes in Biblical and church-planting training in Mexico.\n",
    "Choose one scenario or aspect of this organization which would be amenable or could benefit from agentic AI.\n",
    "Consider possible limitations or challenges in accessing AI and LLM tools from within Mexico.  \n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": content}]\n",
    "\n",
    "# Then make the first call:\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "question = response.choices[0].message.content\n",
    "\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Opportunity Identification:**\\n\\nIn Mexico, there is a growing interest in church planting and biblical training, especially in underserved or rural regions where access to formal theological education is limited. A Christian non-profit organization specializing in **Biblical and church-planting training** could leverage digital tools to expand their reach, provide contextualized theological resources, and support local leaders who might have limited formal training but a strong calling.\\n\\n---\\n\\n### Opportunity:\\n**Developing a localized, AI-powered virtual coaching assistant for church planters and biblical trainees.**\\n\\n---\\n\\n### Scenario for Agentic AI Integration:\\n\\n**Virtual Coaching and Personalized Learning for Church Planters**\\n\\n- **Description:**  \\n  An AI-powered virtual assistant could provide personalized training pathways, scriptural insights, ministry leadership tips, and strategic guidance to church planters in Mexico. This assistant could simulate a knowledgeable mentor that offers contextualized advice based on local culture, language, and ministry challenges. For example:\\n  - Providing biblical exegesis tailored to Latin American cultural contexts.\\n  - Offering church planting strategies suited for rural Mexico.\\n  - Helping trainees practice sermon delivery or Q&A sessions.\\n  - Facilitating community-building by connecting trainees with peers and mentors.\\n\\n- **Agentic AI Role:**  \\n  The AI would act autonomously in guiding learners along customized learning paths, assessing progress, and adapting content dynamically. It could answer questions instantly, provide theological resources, and encourage practical implementation ideas, enhancing the scalability and impact of the organization’s training programs.\\n\\n---\\n\\n### Possible Limitations or Challenges in Accessing AI and LLM Tools from Mexico:\\n\\n1. **Internet Connectivity:**  \\n   Many rural areas in Mexico have limited or unreliable internet access, which can hinder the use of cloud-based AI services that require real-time interaction.\\n\\n2. **Cost and Infrastructure:**  \\n   Access to large language models (LLMs) and advanced AI tools can be expensive. The non-profit may lack budget or infrastructure to deploy and maintain these technologies on-premises and might rely on subscription models or cloud providers.\\n\\n3. **Language and Localization:**  \\n   While Spanish-language models exist, many LLMs perform better in English. There may be gaps in accurately understanding and generating culturally relevant, theologically sound content in Mexican Spanish.\\n\\n4. **Data Privacy and Regulatory Issues:**  \\n   Mexican laws around data protection (e.g., the Federal Law on Protection of Personal Data Held by Private Parties - LFPDPPP) must be adhered to, especially when dealing with personal data from learners or church planters.\\n\\n5. **Digital Literacy:**  \\n   Trainees and local church planters might have varying levels of comfort and familiarity with technology, requiring user-friendly interfaces and training on how to use AI tools effectively.\\n\\n6. **Ethical and Theological Oversight:**  \\n   AI-generated theological content must be carefully reviewed by human experts to ensure doctrinal accuracy and prevent misinformation or theological errors.\\n\\n---\\n\\n### Summary:\\n\\nA Christian non-profit focused on biblical and church-planting training in Mexico can greatly benefit from an agentic AI-driven virtual coaching system that personalizes training and mentorship at scale. Addressing challenges like connectivity, cost, localization, legal compliance, and digital literacy will be key to sustainably implementing such AI-enhanced solutions in the Mexican context.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A key pain-point that an agentic AI solution could address in this context is:\n",
      "\n",
      "### **Limited Access to Contextualized, Personalized Theological Training and Mentorship for Rural Church Planters**\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "Many aspiring church planters in underserved or rural regions of Mexico face significant barriers to receiving formal theological education and tailored mentoring due to:\n",
      "\n",
      "- Scarce local training resources and expert mentors\n",
      "- Varied cultural contexts and linguistic nuances that generic training fails to address\n",
      "- Inability to travel or attend centralized training programs due to geography or cost\n",
      "- Limited ongoing support for practical challenges in their ministries\n",
      "\n",
      "**How Agentic AI Addresses This Pain-Point:**\n",
      "\n",
      "An agentic AI virtual assistant can autonomously:\n",
      "\n",
      "- Deliver personalized, adaptive learning pathways that consider the trainee’s progress, questions, and ministry context\n",
      "- Provide culturally relevant biblical interpretation and ministry advice tailored to the Mexican rural environment\n",
      "- Simulate mentorship interactions, including sermon practice and Q&A, to build confidence and skill\n",
      "- Connect learners with peer communities and human mentors to foster relational support\n",
      "- Continuously assess learners and dynamically adjust content to fill knowledge gaps or address challenges\n",
      "\n",
      "This directly tackles the scarcity of expert human mentorship and formal education by leveraging scalable AI-driven personalized coaching that can work asynchronously and offline (where possible), thereby overcoming geographic and resource limitations.\n",
      "\n",
      "---\n",
      "\n",
      "### Summary:\n",
      "\n",
      "**Pain-point:**  \n",
      "_Rural Mexican church planters lack access to personalized, culturally contextualized theological training and mentorship._\n",
      "\n",
      "**Agentic AI solution:**  \n",
      "An autonomous virtual coaching assistant delivering adaptive, localized theological education and practical ministry guidance at scale, supporting learners despite geographic, infrastructural, or resource constraints.\n"
     ]
    }
   ],
   "source": [
    "# Identify a pain-point:\n",
    "\n",
    "pain_point_prompt = f\"\"\"Identify a potential pain-point that could be addressed by an agentic AI solution. Tne opportunity in question is as follows:\" \\\n",
    "{question}\"\"\"\n",
    "\n",
    "# form a new messages list\n",
    "messages = [{\"role\": \"user\", \"content\": pain_point_prompt}]\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "pain_point = response.choices[0].message.content\n",
    "\n",
    "print(pain_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Here's a detailed proposal for an agentic AI solution tailored specifically to the pain-point you outlined:\n",
      "\n",
      "---\n",
      "\n",
      "## Proposed Agentic AI Solution: **“Semilla Mentor” – Autonomous Theological Coach for Rural Church Planters**\n",
      "\n",
      "### 1. Overview:\n",
      "**Semilla Mentor** is an AI-driven virtual coaching agent designed to provide personalized, culturally contextualized theological education and mentorship to rural church planters in Mexico. It functions autonomously yet offers human-like interactions and adaptive learning tailored to the local language, traditions, and ministry challenges.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. Key Features & Functionalities\n",
      "\n",
      "#### A. Personalized Adaptive Learning Pathways\n",
      "- **Initial Assessment:** Conducts diagnostic evaluations on theological knowledge, ministry experience, cultural context, and language preferences.\n",
      "- **Dynamic Curriculum:** Designs and updates customized lesson plans based on proficiency, ministry focus, and learning pace.\n",
      "- **Microlearning Modules:** Provides bite-sized lessons addressing theological concepts, pastoral skills, and community engagement strategies.\n",
      "- **Offline Access:** Delivers core content downloadable for offline study in areas with poor internet connectivity.\n",
      "\n",
      "#### B. Contextualized Biblical Interpretation & Ministry Guidance\n",
      "- **Cultural Adaptation:** Incorporates regional customs, indigenous languages, and societal norms into biblical applications and examples.\n",
      "- **Case-Based Scenarios:** Offers interpretative guidance reflective of real-world rural ministry challenges typical to Mexican contexts.\n",
      "- **Localization Engine:** Adapts language tone, scripture references, and ministry advice relevant to the learner’s cultural setting.\n",
      "\n",
      "#### C. Simulated Mentorship & Interactive Practice\n",
      "- **AI Roleplay Mentor:** Engages learners in sermon practice, Q&A sessions, and pastoral counseling simulations using natural language dialogue.\n",
      "- **Feedback & Coaching:** Provides constructive critique on sermon structure, theological accuracy, and pastoral approaches.\n",
      "- **Confidence Building:** Uses motivational dialogue and success reinforcement tailored to learner personality and progress.\n",
      "\n",
      "#### D. Peer and Human Mentor Connection\n",
      "- **Community Building:** Facilitates virtual peer groups segmented around language, region, or ministry phase to encourage mutual support.\n",
      "- **Mentor Matching:** Suggests and schedules sessions with remote human mentors for advanced coaching when AI encounters complex issues.\n",
      "- **Shared Resource Library:** Allows users to share sermons, study materials, and ministry tools with their community.\n",
      "\n",
      "#### E. Continuous Performance Analysis & Adjustment\n",
      "- **Progress Tracking:** Monitors knowledge acquisition, engagement levels, and skill development.\n",
      "- **Intelligent Interventions:** Detects emerging challenges or knowledge gaps, proactively offering targeted modules or connecting learners with mentors.\n",
      "- **Feedback Loop:** Learner responses and outcomes continuously train and refine the AI’s pedagogy and cultural models.\n",
      "\n",
      "---\n",
      "\n",
      "### 3. Technical Implementation Considerations\n",
      "\n",
      "- **Multilingual NLP:** Supports Spanish and indigenous languages/dialects common in rural Mexico using specialized language models.\n",
      "- **Mobile-First Design:** Accessible via smartphones (popular in rural settings), with minimal data requirements.\n",
      "- **Edge Compatibility:** Enables offline use with periodic synchronization when connectivity is available.\n",
      "- **Data Privacy:** Ensures secure handling of personal, community, and spiritual information compliant with relevant regulations.\n",
      "- **Explainable AI:** Provides rationale for theological interpretations to build trust and transparency.\n",
      "\n",
      "---\n",
      "\n",
      "### 4. Impact & Benefits\n",
      "\n",
      "- **Democratizes Access:** Removes geographic and economic barriers to quality theological mentoring.\n",
      "- **Enhances Effectiveness:** Tailored content improves relevance and practical applicability in distinct rural contexts.\n",
      "- **Strengthens Local Churches:** Equips planters with confidence, competence, and ongoing support, fostering sustainable ministry growth.\n",
      "- **Scalable & Sustainable:** Reduces dependency on scarce human mentors, reaching more learners concurrently with consistent quality.\n",
      "\n",
      "---\n",
      "\n",
      "### Summary Table:\n",
      "\n",
      "| Feature                         | Description                                         | Benefit                                        |\n",
      "|---------------------------------|-----------------------------------------------------|------------------------------------------------|\n",
      "| Personalized Learning           | Adaptive courses tailored to learner context         | Increases engagement and knowledge retention   |\n",
      "| Contextualized Teaching         | Culturally relevant biblical and ministry insights  | Applies theology meaningfully in local culture |\n",
      "| Interactive Mentorship Simulations | AI-driven dialogue and sermon coaching                | Builds pastoral skills and self-confidence      |\n",
      "| Peer & Mentor Network           | Connects learners with community and expert mentors | Offers relational support and advanced guidance |\n",
      "| Offline & Mobile Access         | Downloadable content & smartphone compatibility     | Overcomes connectivity barriers                  |\n",
      "| Continuous Assessment & Adaptation | Ongoing evaluation with intelligent feedback          | Addresses knowledge gaps in real time            |\n",
      "\n",
      "---\n",
      "\n",
      "Would you like me to draft sample user flows, interface mockups, or an implementation roadmap next?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "opportunity_prompt = f\"\"\"\n",
    "Propose an agentic AI solution to the following pain-point:\n",
    "{pain_point}\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": opportunity_prompt}]\n",
    "\n",
    "# Then make the call:\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "opportunity_idea = response.choices[0].message.content\n",
    "\n",
    "print(opportunity_idea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Opportunity Identification:**\\n\\nIn Mexico, there is a growing interest in church planting and biblical training, especially in underserved or rural regions where access to formal theological education is limited. A Christian non-profit organization specializing in **Biblical and church-planting training** could leverage digital tools to expand their reach, provide contextualized theological resources, and support local leaders who might have limited formal training but a strong calling.\\n\\n---\\n\\n### Opportunity:\\n**Developing a localized, AI-powered virtual coaching assistant for church planters and biblical trainees.**\\n\\n---\\n\\n### Scenario for Agentic AI Integration:\\n\\n**Virtual Coaching and Personalized Learning for Church Planters**\\n\\n- **Description:**  \\n  An AI-powered virtual assistant could provide personalized training pathways, scriptural insights, ministry leadership tips, and strategic guidance to church planters in Mexico. This assistant could simulate a knowledgeable mentor that offers contextualized advice based on local culture, language, and ministry challenges. For example:\\n  - Providing biblical exegesis tailored to Latin American cultural contexts.\\n  - Offering church planting strategies suited for rural Mexico.\\n  - Helping trainees practice sermon delivery or Q&A sessions.\\n  - Facilitating community-building by connecting trainees with peers and mentors.\\n\\n- **Agentic AI Role:**  \\n  The AI would act autonomously in guiding learners along customized learning paths, assessing progress, and adapting content dynamically. It could answer questions instantly, provide theological resources, and encourage practical implementation ideas, enhancing the scalability and impact of the organization’s training programs.\\n\\n---\\n\\n### Possible Limitations or Challenges in Accessing AI and LLM Tools from Mexico:\\n\\n1. **Internet Connectivity:**  \\n   Many rural areas in Mexico have limited or unreliable internet access, which can hinder the use of cloud-based AI services that require real-time interaction.\\n\\n2. **Cost and Infrastructure:**  \\n   Access to large language models (LLMs) and advanced AI tools can be expensive. The non-profit may lack budget or infrastructure to deploy and maintain these technologies on-premises and might rely on subscription models or cloud providers.\\n\\n3. **Language and Localization:**  \\n   While Spanish-language models exist, many LLMs perform better in English. There may be gaps in accurately understanding and generating culturally relevant, theologically sound content in Mexican Spanish.\\n\\n4. **Data Privacy and Regulatory Issues:**  \\n   Mexican laws around data protection (e.g., the Federal Law on Protection of Personal Data Held by Private Parties - LFPDPPP) must be adhered to, especially when dealing with personal data from learners or church planters.\\n\\n5. **Digital Literacy:**  \\n   Trainees and local church planters might have varying levels of comfort and familiarity with technology, requiring user-friendly interfaces and training on how to use AI tools effectively.\\n\\n6. **Ethical and Theological Oversight:**  \\n   AI-generated theological content must be carefully reviewed by human experts to ensure doctrinal accuracy and prevent misinformation or theological errors.\\n\\n---\\n\\n### Summary:\\n\\nA Christian non-profit focused on biblical and church-planting training in Mexico can greatly benefit from an agentic AI-driven virtual coaching system that personalizes training and mentorship at scale. Addressing challenges like connectivity, cost, localization, legal compliance, and digital literacy will be key to sustainably implementing such AI-enhanced solutions in the Mexican context.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markdown saved to c:\\Users\\drhan\\OneDrive\\Documents\\GitHub\\llms\\agents\\1_foundations\\Mexico_AgenticAI_Opportunity.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# import pypandoc   # pip install pypandoc\n",
    "\n",
    "# --- 1. Concatenate the markdown strings ---\n",
    "combined_md = \"\\n\\n\".join([content, question, pain_point, opportunity_idea])\n",
    "\n",
    "# --- 2. Write the markdown file ---\n",
    "md_filename = \"Mexico_AgenticAI_Opportunity.md\"\n",
    "with open(md_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(combined_md)\n",
    "\n",
    "print(f\"Markdown saved to {os.path.abspath(md_filename)}\")\n",
    "\n",
    "# # --- 3. Convert to DOCX ---\n",
    "# docx_filename = \"Mexico_AgenticAI_Opportunity.docx\"\n",
    "# pypandoc.convert_file(\n",
    "#     md_filename,\n",
    "#     to=\"docx\",\n",
    "#     outputfile=docx_filename,\n",
    "# )\n",
    "\n",
    "# print(f\"DOCX saved to {os.path.abspath(docx_filename)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "- Simple **Prompt Chaining** of a series of LLM calls to identify a sector of interest, decide on a pain-point in the sector that could be amenable to an agentic AI solution, and finally, propose a solution. \n",
    "\n",
    "- I used Jim Culp's Igelesias del Oeste Bible/theology training and church planting ministry in Mexico as a case study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
