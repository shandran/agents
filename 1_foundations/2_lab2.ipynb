{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Second Lab - Week 1, Day 3\n",
    "\n",
    "Today we will work with lots of models! This is a way to get comfortable with APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Important point - please read</h2>\n",
    "            <span style=\"color:#ff7800;\">The way I collaborate with you may be different to other courses you've taken. I prefer not to type code while you watch. Rather, I execute Jupyter Labs, like this, and give you an intuition for what's going on. My suggestion is that you carefully execute this yourself, <b>after</b> watching the lecture. Add print statements to understand what's going on, and then come up with your own variations.<br/><br/>If you have time, I'd love it if you submit a PR for changes in the community_contributions folder - instructions in the resources. Also, if you have a Github account, use this to showcase your variations. Not only is this essential practice, but it demonstrates your skills to others, including perhaps future clients or employers...\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with imports - ask ChatGPT to explain any package that you don't know\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "# from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anthropic import Anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Always remember to do this!\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-ant-\n",
      "Google API Key exists and begins AI\n",
      "DeepSeek API Key not set (and this is optional)\n",
      "Groq API Key not set (and this is optional)\n"
     ]
    }
   ],
   "source": [
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set (and this is optional)\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"Groq API Key exists and begins {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Groq API Key not set (and this is optional)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "request += \"Answer only with the question, no explanation.\"\n",
    "messages = [{\"role\": \"user\", \"content\": request}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. Answer only with the question, no explanation.'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a world where artificial intelligence continues to evolve and integrate into daily life, what ethical framework should govern the development and deployment of AI systems to balance innovation with societal risk, and how would you prioritize the interests of different stakeholders involved?\n"
     ]
    }
   ],
   "source": [
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    ")\n",
    "question = response.choices[0].message.content\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors = []\n",
    "answers = []\n",
    "messages = [{\"role\": \"user\", \"content\": question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "In a rapidly advancing technological landscape, establishing an ethical framework for the development and deployment of AI systems is crucial for balancing innovation with societal risks. An effective framework should encompass a combination of principles that prioritize safety, fairness, accountability, transparency, and inclusivity. Here’s a detailed breakdown of how such a framework could be structured and how to prioritize stakeholder interests:\n",
       "\n",
       "### Ethical Framework Components\n",
       "\n",
       "1. **Safety and Security**:\n",
       "   - **Principle**: Ensure that AI systems are designed and rigorously tested to operate safely and securely, minimizing risks to human life and well-being.\n",
       "   - **Implementation**: Mandate safety protocols, continuous monitoring, and the use of best practices in AI development.\n",
       "\n",
       "2. **Fairness and Non-discrimination**:\n",
       "   - **Principle**: Strive for equitable outcomes, preventing biases against any individual or group.\n",
       "   - **Implementation**: Develop algorithms that are tested for bias and subjected to diverse input during both training and evaluation phases.\n",
       "\n",
       "3. **Transparency**:\n",
       "   - **Principle**: Allow stakeholders to understand how AI systems operate and make decisions.\n",
       "   - **Implementation**: Require clear documentation of AI models, decision-making processes, and potential limitations so that users and developers are fully informed.\n",
       "\n",
       "4. **Accountability**:\n",
       "   - **Principle**: Ensure that AI developers and organizations are responsible for the impacts of their technologies.\n",
       "   - **Implementation**: Establish governance structures that include compliance with regulatory standards, ethical reviews, and mechanisms for redress.\n",
       "\n",
       "5. **Inclusivity and Stakeholder Engagement**:\n",
       "   - **Principle**: Engage a diverse range of stakeholders in the development process to understand various perspectives and needs.\n",
       "   - **Implementation**: Foster dialogue with communities affected by AI implementation, considering their input throughout the development lifecycle.\n",
       "\n",
       "6. **Sustainability**:\n",
       "   - **Principle**: Consider the environmental impact of AI technologies and implement practices that promote sustainability.\n",
       "   - **Implementation**: Encourage the development of energy-efficient AI systems and promote technologies that solve real-world problems.\n",
       "\n",
       "### Prioritizing Stakeholder Interests\n",
       "\n",
       "The interests of different stakeholders (users, developers, organizations, regulators, and society at large) can be prioritized through a balanced approach:\n",
       "\n",
       "1. **Users**: Their safety, privacy, and empowerment should be the top priority. They should have access to information about how AI affects their lives and the ability to opt out of systems that do not prioritize their interests.\n",
       "\n",
       "2. **Developers and Organizations**: While innovation and profit motives are important, these must not undermine ethical considerations. Organizations should cultivate a culture of responsibility where ethical practice is integral to business models and not just an afterthought.\n",
       "\n",
       "3. **Regulators and Policymakers**: They should establish clear guidelines and frameworks that ensure ethical AI practices are followed. This includes setting standards for accountability and transparency, as well as inspecting compliance.\n",
       "\n",
       "4. **Society at Large**: Long-term societal impacts should be a crucial consideration. Initiatives should focus on ensuring that AI serves the public good and promotes social welfare, addressing regulatory needs that prioritize collective interests over individual profit.\n",
       "\n",
       "5. **Vulnerable Populations**: Special attention should be given to marginalized and vulnerable groups who might be disproportionately affected by AI technologies. They should have representation in decision-making processes and included in impact assessments.\n",
       "\n",
       "### Conclusion\n",
       "\n",
       "The proposed ethical framework for AI development and deployment emphasizes the need for a comprehensive approach that balances the interests of all stakeholders involved. By placing a strong emphasis on safety, fairness, transparency, and accountability, and by actively engaging diverse voices, we can foster an environment where innovation flourishes while safeguarding societal values and minimizing risks. Implementing such a framework can help ensure that AI technologies contribute positively to society and enhance, rather than undermine, human welfare."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The API we know well\n",
    "# This is asking 40-mini it's own question\n",
    "\n",
    "model_name = \"gpt-4o-mini\"\n",
    "\n",
    "response = openai.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Ethical Framework for AI Development\n",
       "\n",
       "I believe an ethical framework for AI should balance several key principles:\n",
       "\n",
       "1. **Beneficence and non-maleficence** - AI should benefit humanity while minimizing harm\n",
       "2. **Justice and fairness** - Benefits and risks should be distributed equitably\n",
       "3. **Autonomy and human oversight** - Humans should maintain meaningful control\n",
       "4. **Transparency and explainability** - AI systems should be understandable\n",
       "5. **Privacy and data rights** - Personal information should be protected\n",
       "\n",
       "For stakeholder prioritization, I'd suggest a balanced approach where:\n",
       "\n",
       "The wellbeing of the public, especially vulnerable populations, should receive primary consideration. Developer interests in innovation matter significantly but shouldn't override safety. Regulatory bodies serve as essential mediators.\n",
       "\n",
       "The most challenging ethical questions often emerge where these interests conflict—like when rapid innovation might bring both benefits and risks. In these cases, I think transparent, inclusive governance processes are crucial, where diverse voices help shape how we proceed with AI development.\n",
       "\n",
       "What aspects of AI ethics are you most concerned about?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Anthropic has a slightly different API, and Max Tokens is required\n",
    "\n",
    "model_name = \"claude-3-7-sonnet-latest\"\n",
    "\n",
    "claude = Anthropic()\n",
    "response = claude.messages.create(model=model_name, messages=messages, max_tokens=1000)\n",
    "answer = response.content[0].text\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The ethical framework governing the development and deployment of AI needs to be multi-faceted, balancing innovation with societal risk by focusing on **human flourishing, fairness, accountability, transparency, and sustainability.**\n",
       "\n",
       "Here's a breakdown of the proposed framework and how it prioritizes stakeholders:\n",
       "\n",
       "**I. The Ethical Framework (FOCUS):**\n",
       "\n",
       "*   **F**airness & Justice:\n",
       "    *   **Goal:**  Ensure equitable access to AI benefits and mitigate bias to prevent discrimination.\n",
       "    *   **Implementation:** Rigorous testing for bias across diverse datasets.  Explainable AI (XAI) techniques to understand decision-making.  Robust auditing processes.  Focus on representing diverse perspectives in AI design and development teams.\n",
       "*   **O**utcomes Focused:\n",
       "    *   **Goal:** Prioritize beneficial and desirable outcomes for humanity and the planet.\n",
       "    *   **Implementation:** Conduct thorough impact assessments prior to deployment.  Develop AI systems aligned with the UN Sustainable Development Goals and other agreed-upon societal priorities.  Embrace a value-sensitive design approach from the outset.\n",
       "*   **C**ontrol & Accountability:\n",
       "    *   **Goal:** Define clear lines of responsibility for AI systems' actions and ensure human oversight where necessary.\n",
       "    *   **Implementation:**  Establish clear accountability frameworks for developers, deployers, and users of AI.  Implement robust error handling and fail-safe mechanisms.  Require human-in-the-loop decision-making for high-stakes applications (e.g., healthcare, criminal justice). Implement red teaming to uncover potential vulnerabilities.\n",
       "*   **U**nderstanding & Transparency:\n",
       "    *   **Goal:** Promote understanding of how AI systems work and make decisions.\n",
       "    *   **Implementation:**  Develop explainable AI (XAI) techniques to make AI decision-making more transparent.  Ensure clear communication to users about the capabilities and limitations of AI systems.  Promote open-source AI development where feasible. Establish processes for users to understand the rationales behind AI decisions affecting them.\n",
       "*   **S**ustainability & Responsibility:\n",
       "    *   **Goal:** Consider the long-term environmental and societal impact of AI development.\n",
       "    *   **Implementation:**  Promote energy-efficient AI models and hardware.  Consider the impact on employment and skills development.  Address potential misuse of AI for malicious purposes (e.g., deepfakes, autonomous weapons). Implement AI safety research focused on avoiding unintended consequences.  Promote responsible data management and privacy.\n",
       "\n",
       "**II. Stakeholder Prioritization & Balancing:**\n",
       "\n",
       "Prioritization is complex, as the interests of stakeholders often overlap and conflict.  A successful framework must strive for a **delicate balance**, emphasizing certain principles based on the specific context.  Here's a broad overview:\n",
       "\n",
       "1.  **Individuals & Vulnerable Groups (Highest Priority in Many Cases):**\n",
       "    *   **Interests:**  Safety, well-being, autonomy, dignity, privacy, fairness, access to opportunities.\n",
       "    *   **Prioritization:** Protection from harm (physical, psychological, economic), equitable access to AI benefits, clear recourse mechanisms when harmed by AI systems, and the right to be informed about AI interactions. Prioritize applications of AI which benefit vulnerable groups.\n",
       "    *   **Balancing:** Must be balanced against the needs of public safety and national security.\n",
       "2.  **The Public (High Priority):**\n",
       "    *   **Interests:**  Societal benefit, public safety, economic growth, democratic values, environmental sustainability.\n",
       "    *   **Prioritization:** AI development should align with broader societal goals.  Public awareness and education about AI.  Democratic oversight of AI development and deployment.  Regulation to prevent harm and promote responsible innovation.\n",
       "    *   **Balancing:**  Must be balanced against the rights of individuals and the need for innovation.\n",
       "3.  **Researchers & Developers (Important):**\n",
       "    *   **Interests:**  Academic freedom, innovation, economic opportunity, recognition for their work.\n",
       "    *   **Prioritization:**  Support for basic AI research.  Access to data and resources.  Clear ethical guidelines and regulatory frameworks.  Protection of intellectual property.\n",
       "    *   **Balancing:** Must be balanced against the need for public safety and ethical considerations. Incentivize development of AI systems which align with the framework’s goals.\n",
       "4.  **Businesses & Organizations (Important):**\n",
       "    *   **Interests:**  Profitability, efficiency, competitive advantage, innovation.\n",
       "    *   **Prioritization:**  Clear regulatory frameworks.  Access to talent and resources.  Support for innovation.\n",
       "    *   **Balancing:**  Must be balanced against the need for societal benefit, fairness, and environmental sustainability. Businesses should be incentivized to incorporate ethical considerations into their AI development processes.\n",
       "5.  **Governments & Regulators (Essential):**\n",
       "    *   **Interests:**  National security, economic growth, public safety, social order, democratic governance.\n",
       "    *   **Prioritization:**  Developing and enforcing ethical guidelines and regulations.  Investing in AI research and development.  Promoting public awareness and education.  International cooperation.\n",
       "    *   **Balancing:** Must be balanced against the need for individual freedoms, innovation, and economic growth.\n",
       "\n",
       "**III. Key Considerations for Implementation:**\n",
       "\n",
       "*   **Context-Specificity:** The framework should be adaptable to different contexts and applications.\n",
       "*   **Continuous Monitoring & Evaluation:**  The framework should be regularly reviewed and updated to reflect advances in AI technology and societal values.\n",
       "*   **Multi-Stakeholder Engagement:** The development and implementation of the framework should involve representatives from all relevant stakeholder groups.\n",
       "*   **International Cooperation:** Given the global nature of AI, international cooperation is essential to ensure consistency and avoid regulatory fragmentation.\n",
       "*   **Education and Training:** Widespread education and training on AI ethics and responsible AI development are crucial for fostering a culture of ethical AI.\n",
       "*   **Redress Mechanisms:** Effective mechanisms for redress and accountability must be available to individuals and groups harmed by AI systems.\n",
       "*   **Regulation and Soft Law:** Combine regulatory oversight with industry self-regulation, standards development, and ethical codes of conduct.\n",
       "\n",
       "**Conclusion:**\n",
       "\n",
       "This proposed ethical framework, \"FOCUS,\" provides a foundation for navigating the complex ethical challenges of AI. By prioritizing fairness, focusing on beneficial outcomes, ensuring accountability, promoting transparency, and emphasizing sustainability, we can harness the transformative potential of AI while mitigating its risks and ensuring a future where AI benefits all of humanity. The key lies in continuous dialogue, adaptation, and a commitment to prioritizing human values in the age of AI.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "model_name = \"gemini-2.0-flash\"\n",
    "\n",
    "response = gemini.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deepseek = OpenAI(api_key=deepseek_api_key, base_url=\"https://api.deepseek.com/v1\")\n",
    "# model_name = \"deepseek-chat\"\n",
    "\n",
    "# response = deepseek.chat.completions.create(model=model_name, messages=messages)\n",
    "# answer = response.choices[0].message.content\n",
    "\n",
    "# display(Markdown(answer))\n",
    "# competitors.append(model_name)\n",
    "# answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groq = OpenAI(api_key=groq_api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
    "# model_name = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "# response = groq.chat.completions.create(model=model_name, messages=messages)\n",
    "# answer = response.choices[0].message.content\n",
    "\n",
    "# display(Markdown(answer))\n",
    "# competitors.append(model_name)\n",
    "# answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the next cell, we will use Ollama\n",
    "\n",
    "Ollama runs a local web service that gives an OpenAI compatible endpoint,  \n",
    "and runs models locally using high performance C++ code.\n",
    "\n",
    "If you don't have Ollama, install it here by visiting https://ollama.com then pressing Download and following the instructions.\n",
    "\n",
    "After it's installed, you should be able to visit here: http://localhost:11434 and see the message \"Ollama is running\"\n",
    "\n",
    "You might need to restart Cursor (and maybe reboot). Then open a Terminal (control+\\`) and run `ollama serve`\n",
    "\n",
    "Useful Ollama commands (run these in the terminal, or with an exclamation mark in this notebook):\n",
    "\n",
    "`ollama pull <model_name>` downloads a model locally  \n",
    "`ollama ls` lists all the models you've downloaded  \n",
    "`ollama rm <model_name>` deletes the specified model from your downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Super important - ignore me at your peril!</h2>\n",
    "            <span style=\"color:#ff7800;\">The model called <b>llama3.3</b> is FAR too large for home computers - it's not intended for personal computing and will consume all your resources! Stick with the nicely sized <b>llama3.2</b> or <b>llama3.2:1b</b> and if you want larger, try llama3.1 or smaller variants of Qwen, Gemma, Phi or DeepSeek. See the <A href=\"https://ollama.com/models\">the Ollama models page</a> for a full list of models and sizes.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "# model_name = \"llama3.2\"\n",
    "\n",
    "# response = ollama.chat.completions.create(model=model_name, messages=messages)\n",
    "# answer = response.choices[0].message.content\n",
    "\n",
    "# display(Markdown(answer))\n",
    "# competitors.append(model_name)\n",
    "# answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt-4o-mini', 'claude-3-7-sonnet-latest', 'gemini-2.0-flash']\n",
      "['In a rapidly advancing technological landscape, establishing an ethical framework for the development and deployment of AI systems is crucial for balancing innovation with societal risks. An effective framework should encompass a combination of principles that prioritize safety, fairness, accountability, transparency, and inclusivity. Here’s a detailed breakdown of how such a framework could be structured and how to prioritize stakeholder interests:\\n\\n### Ethical Framework Components\\n\\n1. **Safety and Security**:\\n   - **Principle**: Ensure that AI systems are designed and rigorously tested to operate safely and securely, minimizing risks to human life and well-being.\\n   - **Implementation**: Mandate safety protocols, continuous monitoring, and the use of best practices in AI development.\\n\\n2. **Fairness and Non-discrimination**:\\n   - **Principle**: Strive for equitable outcomes, preventing biases against any individual or group.\\n   - **Implementation**: Develop algorithms that are tested for bias and subjected to diverse input during both training and evaluation phases.\\n\\n3. **Transparency**:\\n   - **Principle**: Allow stakeholders to understand how AI systems operate and make decisions.\\n   - **Implementation**: Require clear documentation of AI models, decision-making processes, and potential limitations so that users and developers are fully informed.\\n\\n4. **Accountability**:\\n   - **Principle**: Ensure that AI developers and organizations are responsible for the impacts of their technologies.\\n   - **Implementation**: Establish governance structures that include compliance with regulatory standards, ethical reviews, and mechanisms for redress.\\n\\n5. **Inclusivity and Stakeholder Engagement**:\\n   - **Principle**: Engage a diverse range of stakeholders in the development process to understand various perspectives and needs.\\n   - **Implementation**: Foster dialogue with communities affected by AI implementation, considering their input throughout the development lifecycle.\\n\\n6. **Sustainability**:\\n   - **Principle**: Consider the environmental impact of AI technologies and implement practices that promote sustainability.\\n   - **Implementation**: Encourage the development of energy-efficient AI systems and promote technologies that solve real-world problems.\\n\\n### Prioritizing Stakeholder Interests\\n\\nThe interests of different stakeholders (users, developers, organizations, regulators, and society at large) can be prioritized through a balanced approach:\\n\\n1. **Users**: Their safety, privacy, and empowerment should be the top priority. They should have access to information about how AI affects their lives and the ability to opt out of systems that do not prioritize their interests.\\n\\n2. **Developers and Organizations**: While innovation and profit motives are important, these must not undermine ethical considerations. Organizations should cultivate a culture of responsibility where ethical practice is integral to business models and not just an afterthought.\\n\\n3. **Regulators and Policymakers**: They should establish clear guidelines and frameworks that ensure ethical AI practices are followed. This includes setting standards for accountability and transparency, as well as inspecting compliance.\\n\\n4. **Society at Large**: Long-term societal impacts should be a crucial consideration. Initiatives should focus on ensuring that AI serves the public good and promotes social welfare, addressing regulatory needs that prioritize collective interests over individual profit.\\n\\n5. **Vulnerable Populations**: Special attention should be given to marginalized and vulnerable groups who might be disproportionately affected by AI technologies. They should have representation in decision-making processes and included in impact assessments.\\n\\n### Conclusion\\n\\nThe proposed ethical framework for AI development and deployment emphasizes the need for a comprehensive approach that balances the interests of all stakeholders involved. By placing a strong emphasis on safety, fairness, transparency, and accountability, and by actively engaging diverse voices, we can foster an environment where innovation flourishes while safeguarding societal values and minimizing risks. Implementing such a framework can help ensure that AI technologies contribute positively to society and enhance, rather than undermine, human welfare.', \"# Ethical Framework for AI Development\\n\\nI believe an ethical framework for AI should balance several key principles:\\n\\n1. **Beneficence and non-maleficence** - AI should benefit humanity while minimizing harm\\n2. **Justice and fairness** - Benefits and risks should be distributed equitably\\n3. **Autonomy and human oversight** - Humans should maintain meaningful control\\n4. **Transparency and explainability** - AI systems should be understandable\\n5. **Privacy and data rights** - Personal information should be protected\\n\\nFor stakeholder prioritization, I'd suggest a balanced approach where:\\n\\nThe wellbeing of the public, especially vulnerable populations, should receive primary consideration. Developer interests in innovation matter significantly but shouldn't override safety. Regulatory bodies serve as essential mediators.\\n\\nThe most challenging ethical questions often emerge where these interests conflict—like when rapid innovation might bring both benefits and risks. In these cases, I think transparent, inclusive governance processes are crucial, where diverse voices help shape how we proceed with AI development.\\n\\nWhat aspects of AI ethics are you most concerned about?\", 'The ethical framework governing the development and deployment of AI needs to be multi-faceted, balancing innovation with societal risk by focusing on **human flourishing, fairness, accountability, transparency, and sustainability.**\\n\\nHere\\'s a breakdown of the proposed framework and how it prioritizes stakeholders:\\n\\n**I. The Ethical Framework (FOCUS):**\\n\\n*   **F**airness & Justice:\\n    *   **Goal:**  Ensure equitable access to AI benefits and mitigate bias to prevent discrimination.\\n    *   **Implementation:** Rigorous testing for bias across diverse datasets.  Explainable AI (XAI) techniques to understand decision-making.  Robust auditing processes.  Focus on representing diverse perspectives in AI design and development teams.\\n*   **O**utcomes Focused:\\n    *   **Goal:** Prioritize beneficial and desirable outcomes for humanity and the planet.\\n    *   **Implementation:** Conduct thorough impact assessments prior to deployment.  Develop AI systems aligned with the UN Sustainable Development Goals and other agreed-upon societal priorities.  Embrace a value-sensitive design approach from the outset.\\n*   **C**ontrol & Accountability:\\n    *   **Goal:** Define clear lines of responsibility for AI systems\\' actions and ensure human oversight where necessary.\\n    *   **Implementation:**  Establish clear accountability frameworks for developers, deployers, and users of AI.  Implement robust error handling and fail-safe mechanisms.  Require human-in-the-loop decision-making for high-stakes applications (e.g., healthcare, criminal justice). Implement red teaming to uncover potential vulnerabilities.\\n*   **U**nderstanding & Transparency:\\n    *   **Goal:** Promote understanding of how AI systems work and make decisions.\\n    *   **Implementation:**  Develop explainable AI (XAI) techniques to make AI decision-making more transparent.  Ensure clear communication to users about the capabilities and limitations of AI systems.  Promote open-source AI development where feasible. Establish processes for users to understand the rationales behind AI decisions affecting them.\\n*   **S**ustainability & Responsibility:\\n    *   **Goal:** Consider the long-term environmental and societal impact of AI development.\\n    *   **Implementation:**  Promote energy-efficient AI models and hardware.  Consider the impact on employment and skills development.  Address potential misuse of AI for malicious purposes (e.g., deepfakes, autonomous weapons). Implement AI safety research focused on avoiding unintended consequences.  Promote responsible data management and privacy.\\n\\n**II. Stakeholder Prioritization & Balancing:**\\n\\nPrioritization is complex, as the interests of stakeholders often overlap and conflict.  A successful framework must strive for a **delicate balance**, emphasizing certain principles based on the specific context.  Here\\'s a broad overview:\\n\\n1.  **Individuals & Vulnerable Groups (Highest Priority in Many Cases):**\\n    *   **Interests:**  Safety, well-being, autonomy, dignity, privacy, fairness, access to opportunities.\\n    *   **Prioritization:** Protection from harm (physical, psychological, economic), equitable access to AI benefits, clear recourse mechanisms when harmed by AI systems, and the right to be informed about AI interactions. Prioritize applications of AI which benefit vulnerable groups.\\n    *   **Balancing:** Must be balanced against the needs of public safety and national security.\\n2.  **The Public (High Priority):**\\n    *   **Interests:**  Societal benefit, public safety, economic growth, democratic values, environmental sustainability.\\n    *   **Prioritization:** AI development should align with broader societal goals.  Public awareness and education about AI.  Democratic oversight of AI development and deployment.  Regulation to prevent harm and promote responsible innovation.\\n    *   **Balancing:**  Must be balanced against the rights of individuals and the need for innovation.\\n3.  **Researchers & Developers (Important):**\\n    *   **Interests:**  Academic freedom, innovation, economic opportunity, recognition for their work.\\n    *   **Prioritization:**  Support for basic AI research.  Access to data and resources.  Clear ethical guidelines and regulatory frameworks.  Protection of intellectual property.\\n    *   **Balancing:** Must be balanced against the need for public safety and ethical considerations. Incentivize development of AI systems which align with the framework’s goals.\\n4.  **Businesses & Organizations (Important):**\\n    *   **Interests:**  Profitability, efficiency, competitive advantage, innovation.\\n    *   **Prioritization:**  Clear regulatory frameworks.  Access to talent and resources.  Support for innovation.\\n    *   **Balancing:**  Must be balanced against the need for societal benefit, fairness, and environmental sustainability. Businesses should be incentivized to incorporate ethical considerations into their AI development processes.\\n5.  **Governments & Regulators (Essential):**\\n    *   **Interests:**  National security, economic growth, public safety, social order, democratic governance.\\n    *   **Prioritization:**  Developing and enforcing ethical guidelines and regulations.  Investing in AI research and development.  Promoting public awareness and education.  International cooperation.\\n    *   **Balancing:** Must be balanced against the need for individual freedoms, innovation, and economic growth.\\n\\n**III. Key Considerations for Implementation:**\\n\\n*   **Context-Specificity:** The framework should be adaptable to different contexts and applications.\\n*   **Continuous Monitoring & Evaluation:**  The framework should be regularly reviewed and updated to reflect advances in AI technology and societal values.\\n*   **Multi-Stakeholder Engagement:** The development and implementation of the framework should involve representatives from all relevant stakeholder groups.\\n*   **International Cooperation:** Given the global nature of AI, international cooperation is essential to ensure consistency and avoid regulatory fragmentation.\\n*   **Education and Training:** Widespread education and training on AI ethics and responsible AI development are crucial for fostering a culture of ethical AI.\\n*   **Redress Mechanisms:** Effective mechanisms for redress and accountability must be available to individuals and groups harmed by AI systems.\\n*   **Regulation and Soft Law:** Combine regulatory oversight with industry self-regulation, standards development, and ethical codes of conduct.\\n\\n**Conclusion:**\\n\\nThis proposed ethical framework, \"FOCUS,\" provides a foundation for navigating the complex ethical challenges of AI. By prioritizing fairness, focusing on beneficial outcomes, ensuring accountability, promoting transparency, and emphasizing sustainability, we can harness the transformative potential of AI while mitigating its risks and ensuring a future where AI benefits all of humanity. The key lies in continuous dialogue, adaptation, and a commitment to prioritizing human values in the age of AI.\\n']\n"
     ]
    }
   ],
   "source": [
    "# So where are we?\n",
    "\n",
    "print(competitors)\n",
    "print(answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Competitor: gpt-4o-mini\n",
      "\n",
      "In a rapidly advancing technological landscape, establishing an ethical framework for the development and deployment of AI systems is crucial for balancing innovation with societal risks. An effective framework should encompass a combination of principles that prioritize safety, fairness, accountability, transparency, and inclusivity. Here’s a detailed breakdown of how such a framework could be structured and how to prioritize stakeholder interests:\n",
      "\n",
      "### Ethical Framework Components\n",
      "\n",
      "1. **Safety and Security**:\n",
      "   - **Principle**: Ensure that AI systems are designed and rigorously tested to operate safely and securely, minimizing risks to human life and well-being.\n",
      "   - **Implementation**: Mandate safety protocols, continuous monitoring, and the use of best practices in AI development.\n",
      "\n",
      "2. **Fairness and Non-discrimination**:\n",
      "   - **Principle**: Strive for equitable outcomes, preventing biases against any individual or group.\n",
      "   - **Implementation**: Develop algorithms that are tested for bias and subjected to diverse input during both training and evaluation phases.\n",
      "\n",
      "3. **Transparency**:\n",
      "   - **Principle**: Allow stakeholders to understand how AI systems operate and make decisions.\n",
      "   - **Implementation**: Require clear documentation of AI models, decision-making processes, and potential limitations so that users and developers are fully informed.\n",
      "\n",
      "4. **Accountability**:\n",
      "   - **Principle**: Ensure that AI developers and organizations are responsible for the impacts of their technologies.\n",
      "   - **Implementation**: Establish governance structures that include compliance with regulatory standards, ethical reviews, and mechanisms for redress.\n",
      "\n",
      "5. **Inclusivity and Stakeholder Engagement**:\n",
      "   - **Principle**: Engage a diverse range of stakeholders in the development process to understand various perspectives and needs.\n",
      "   - **Implementation**: Foster dialogue with communities affected by AI implementation, considering their input throughout the development lifecycle.\n",
      "\n",
      "6. **Sustainability**:\n",
      "   - **Principle**: Consider the environmental impact of AI technologies and implement practices that promote sustainability.\n",
      "   - **Implementation**: Encourage the development of energy-efficient AI systems and promote technologies that solve real-world problems.\n",
      "\n",
      "### Prioritizing Stakeholder Interests\n",
      "\n",
      "The interests of different stakeholders (users, developers, organizations, regulators, and society at large) can be prioritized through a balanced approach:\n",
      "\n",
      "1. **Users**: Their safety, privacy, and empowerment should be the top priority. They should have access to information about how AI affects their lives and the ability to opt out of systems that do not prioritize their interests.\n",
      "\n",
      "2. **Developers and Organizations**: While innovation and profit motives are important, these must not undermine ethical considerations. Organizations should cultivate a culture of responsibility where ethical practice is integral to business models and not just an afterthought.\n",
      "\n",
      "3. **Regulators and Policymakers**: They should establish clear guidelines and frameworks that ensure ethical AI practices are followed. This includes setting standards for accountability and transparency, as well as inspecting compliance.\n",
      "\n",
      "4. **Society at Large**: Long-term societal impacts should be a crucial consideration. Initiatives should focus on ensuring that AI serves the public good and promotes social welfare, addressing regulatory needs that prioritize collective interests over individual profit.\n",
      "\n",
      "5. **Vulnerable Populations**: Special attention should be given to marginalized and vulnerable groups who might be disproportionately affected by AI technologies. They should have representation in decision-making processes and included in impact assessments.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "The proposed ethical framework for AI development and deployment emphasizes the need for a comprehensive approach that balances the interests of all stakeholders involved. By placing a strong emphasis on safety, fairness, transparency, and accountability, and by actively engaging diverse voices, we can foster an environment where innovation flourishes while safeguarding societal values and minimizing risks. Implementing such a framework can help ensure that AI technologies contribute positively to society and enhance, rather than undermine, human welfare.\n",
      "Competitor: claude-3-7-sonnet-latest\n",
      "\n",
      "# Ethical Framework for AI Development\n",
      "\n",
      "I believe an ethical framework for AI should balance several key principles:\n",
      "\n",
      "1. **Beneficence and non-maleficence** - AI should benefit humanity while minimizing harm\n",
      "2. **Justice and fairness** - Benefits and risks should be distributed equitably\n",
      "3. **Autonomy and human oversight** - Humans should maintain meaningful control\n",
      "4. **Transparency and explainability** - AI systems should be understandable\n",
      "5. **Privacy and data rights** - Personal information should be protected\n",
      "\n",
      "For stakeholder prioritization, I'd suggest a balanced approach where:\n",
      "\n",
      "The wellbeing of the public, especially vulnerable populations, should receive primary consideration. Developer interests in innovation matter significantly but shouldn't override safety. Regulatory bodies serve as essential mediators.\n",
      "\n",
      "The most challenging ethical questions often emerge where these interests conflict—like when rapid innovation might bring both benefits and risks. In these cases, I think transparent, inclusive governance processes are crucial, where diverse voices help shape how we proceed with AI development.\n",
      "\n",
      "What aspects of AI ethics are you most concerned about?\n",
      "Competitor: gemini-2.0-flash\n",
      "\n",
      "The ethical framework governing the development and deployment of AI needs to be multi-faceted, balancing innovation with societal risk by focusing on **human flourishing, fairness, accountability, transparency, and sustainability.**\n",
      "\n",
      "Here's a breakdown of the proposed framework and how it prioritizes stakeholders:\n",
      "\n",
      "**I. The Ethical Framework (FOCUS):**\n",
      "\n",
      "*   **F**airness & Justice:\n",
      "    *   **Goal:**  Ensure equitable access to AI benefits and mitigate bias to prevent discrimination.\n",
      "    *   **Implementation:** Rigorous testing for bias across diverse datasets.  Explainable AI (XAI) techniques to understand decision-making.  Robust auditing processes.  Focus on representing diverse perspectives in AI design and development teams.\n",
      "*   **O**utcomes Focused:\n",
      "    *   **Goal:** Prioritize beneficial and desirable outcomes for humanity and the planet.\n",
      "    *   **Implementation:** Conduct thorough impact assessments prior to deployment.  Develop AI systems aligned with the UN Sustainable Development Goals and other agreed-upon societal priorities.  Embrace a value-sensitive design approach from the outset.\n",
      "*   **C**ontrol & Accountability:\n",
      "    *   **Goal:** Define clear lines of responsibility for AI systems' actions and ensure human oversight where necessary.\n",
      "    *   **Implementation:**  Establish clear accountability frameworks for developers, deployers, and users of AI.  Implement robust error handling and fail-safe mechanisms.  Require human-in-the-loop decision-making for high-stakes applications (e.g., healthcare, criminal justice). Implement red teaming to uncover potential vulnerabilities.\n",
      "*   **U**nderstanding & Transparency:\n",
      "    *   **Goal:** Promote understanding of how AI systems work and make decisions.\n",
      "    *   **Implementation:**  Develop explainable AI (XAI) techniques to make AI decision-making more transparent.  Ensure clear communication to users about the capabilities and limitations of AI systems.  Promote open-source AI development where feasible. Establish processes for users to understand the rationales behind AI decisions affecting them.\n",
      "*   **S**ustainability & Responsibility:\n",
      "    *   **Goal:** Consider the long-term environmental and societal impact of AI development.\n",
      "    *   **Implementation:**  Promote energy-efficient AI models and hardware.  Consider the impact on employment and skills development.  Address potential misuse of AI for malicious purposes (e.g., deepfakes, autonomous weapons). Implement AI safety research focused on avoiding unintended consequences.  Promote responsible data management and privacy.\n",
      "\n",
      "**II. Stakeholder Prioritization & Balancing:**\n",
      "\n",
      "Prioritization is complex, as the interests of stakeholders often overlap and conflict.  A successful framework must strive for a **delicate balance**, emphasizing certain principles based on the specific context.  Here's a broad overview:\n",
      "\n",
      "1.  **Individuals & Vulnerable Groups (Highest Priority in Many Cases):**\n",
      "    *   **Interests:**  Safety, well-being, autonomy, dignity, privacy, fairness, access to opportunities.\n",
      "    *   **Prioritization:** Protection from harm (physical, psychological, economic), equitable access to AI benefits, clear recourse mechanisms when harmed by AI systems, and the right to be informed about AI interactions. Prioritize applications of AI which benefit vulnerable groups.\n",
      "    *   **Balancing:** Must be balanced against the needs of public safety and national security.\n",
      "2.  **The Public (High Priority):**\n",
      "    *   **Interests:**  Societal benefit, public safety, economic growth, democratic values, environmental sustainability.\n",
      "    *   **Prioritization:** AI development should align with broader societal goals.  Public awareness and education about AI.  Democratic oversight of AI development and deployment.  Regulation to prevent harm and promote responsible innovation.\n",
      "    *   **Balancing:**  Must be balanced against the rights of individuals and the need for innovation.\n",
      "3.  **Researchers & Developers (Important):**\n",
      "    *   **Interests:**  Academic freedom, innovation, economic opportunity, recognition for their work.\n",
      "    *   **Prioritization:**  Support for basic AI research.  Access to data and resources.  Clear ethical guidelines and regulatory frameworks.  Protection of intellectual property.\n",
      "    *   **Balancing:** Must be balanced against the need for public safety and ethical considerations. Incentivize development of AI systems which align with the framework’s goals.\n",
      "4.  **Businesses & Organizations (Important):**\n",
      "    *   **Interests:**  Profitability, efficiency, competitive advantage, innovation.\n",
      "    *   **Prioritization:**  Clear regulatory frameworks.  Access to talent and resources.  Support for innovation.\n",
      "    *   **Balancing:**  Must be balanced against the need for societal benefit, fairness, and environmental sustainability. Businesses should be incentivized to incorporate ethical considerations into their AI development processes.\n",
      "5.  **Governments & Regulators (Essential):**\n",
      "    *   **Interests:**  National security, economic growth, public safety, social order, democratic governance.\n",
      "    *   **Prioritization:**  Developing and enforcing ethical guidelines and regulations.  Investing in AI research and development.  Promoting public awareness and education.  International cooperation.\n",
      "    *   **Balancing:** Must be balanced against the need for individual freedoms, innovation, and economic growth.\n",
      "\n",
      "**III. Key Considerations for Implementation:**\n",
      "\n",
      "*   **Context-Specificity:** The framework should be adaptable to different contexts and applications.\n",
      "*   **Continuous Monitoring & Evaluation:**  The framework should be regularly reviewed and updated to reflect advances in AI technology and societal values.\n",
      "*   **Multi-Stakeholder Engagement:** The development and implementation of the framework should involve representatives from all relevant stakeholder groups.\n",
      "*   **International Cooperation:** Given the global nature of AI, international cooperation is essential to ensure consistency and avoid regulatory fragmentation.\n",
      "*   **Education and Training:** Widespread education and training on AI ethics and responsible AI development are crucial for fostering a culture of ethical AI.\n",
      "*   **Redress Mechanisms:** Effective mechanisms for redress and accountability must be available to individuals and groups harmed by AI systems.\n",
      "*   **Regulation and Soft Law:** Combine regulatory oversight with industry self-regulation, standards development, and ethical codes of conduct.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "This proposed ethical framework, \"FOCUS,\" provides a foundation for navigating the complex ethical challenges of AI. By prioritizing fairness, focusing on beneficial outcomes, ensuring accountability, promoting transparency, and emphasizing sustainability, we can harness the transformative potential of AI while mitigating its risks and ensuring a future where AI benefits all of humanity. The key lies in continuous dialogue, adaptation, and a commitment to prioritizing human values in the age of AI.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# It's nice to know how to use \"zip\"\n",
    "for competitor, answer in zip(competitors, answers):\n",
    "    print(f\"Competitor: {competitor}\\n\\n{answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's bring this together - note the use of \"enumerate\"\n",
    "\n",
    "together = \"\"\n",
    "for index, answer in enumerate(answers):\n",
    "    together += f\"# Response from competitor {index+1}\\n\\n\"\n",
    "    together += answer + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Response from competitor 1\n",
      "\n",
      "In a rapidly advancing technological landscape, establishing an ethical framework for the development and deployment of AI systems is crucial for balancing innovation with societal risks. An effective framework should encompass a combination of principles that prioritize safety, fairness, accountability, transparency, and inclusivity. Here’s a detailed breakdown of how such a framework could be structured and how to prioritize stakeholder interests:\n",
      "\n",
      "### Ethical Framework Components\n",
      "\n",
      "1. **Safety and Security**:\n",
      "   - **Principle**: Ensure that AI systems are designed and rigorously tested to operate safely and securely, minimizing risks to human life and well-being.\n",
      "   - **Implementation**: Mandate safety protocols, continuous monitoring, and the use of best practices in AI development.\n",
      "\n",
      "2. **Fairness and Non-discrimination**:\n",
      "   - **Principle**: Strive for equitable outcomes, preventing biases against any individual or group.\n",
      "   - **Implementation**: Develop algorithms that are tested for bias and subjected to diverse input during both training and evaluation phases.\n",
      "\n",
      "3. **Transparency**:\n",
      "   - **Principle**: Allow stakeholders to understand how AI systems operate and make decisions.\n",
      "   - **Implementation**: Require clear documentation of AI models, decision-making processes, and potential limitations so that users and developers are fully informed.\n",
      "\n",
      "4. **Accountability**:\n",
      "   - **Principle**: Ensure that AI developers and organizations are responsible for the impacts of their technologies.\n",
      "   - **Implementation**: Establish governance structures that include compliance with regulatory standards, ethical reviews, and mechanisms for redress.\n",
      "\n",
      "5. **Inclusivity and Stakeholder Engagement**:\n",
      "   - **Principle**: Engage a diverse range of stakeholders in the development process to understand various perspectives and needs.\n",
      "   - **Implementation**: Foster dialogue with communities affected by AI implementation, considering their input throughout the development lifecycle.\n",
      "\n",
      "6. **Sustainability**:\n",
      "   - **Principle**: Consider the environmental impact of AI technologies and implement practices that promote sustainability.\n",
      "   - **Implementation**: Encourage the development of energy-efficient AI systems and promote technologies that solve real-world problems.\n",
      "\n",
      "### Prioritizing Stakeholder Interests\n",
      "\n",
      "The interests of different stakeholders (users, developers, organizations, regulators, and society at large) can be prioritized through a balanced approach:\n",
      "\n",
      "1. **Users**: Their safety, privacy, and empowerment should be the top priority. They should have access to information about how AI affects their lives and the ability to opt out of systems that do not prioritize their interests.\n",
      "\n",
      "2. **Developers and Organizations**: While innovation and profit motives are important, these must not undermine ethical considerations. Organizations should cultivate a culture of responsibility where ethical practice is integral to business models and not just an afterthought.\n",
      "\n",
      "3. **Regulators and Policymakers**: They should establish clear guidelines and frameworks that ensure ethical AI practices are followed. This includes setting standards for accountability and transparency, as well as inspecting compliance.\n",
      "\n",
      "4. **Society at Large**: Long-term societal impacts should be a crucial consideration. Initiatives should focus on ensuring that AI serves the public good and promotes social welfare, addressing regulatory needs that prioritize collective interests over individual profit.\n",
      "\n",
      "5. **Vulnerable Populations**: Special attention should be given to marginalized and vulnerable groups who might be disproportionately affected by AI technologies. They should have representation in decision-making processes and included in impact assessments.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "The proposed ethical framework for AI development and deployment emphasizes the need for a comprehensive approach that balances the interests of all stakeholders involved. By placing a strong emphasis on safety, fairness, transparency, and accountability, and by actively engaging diverse voices, we can foster an environment where innovation flourishes while safeguarding societal values and minimizing risks. Implementing such a framework can help ensure that AI technologies contribute positively to society and enhance, rather than undermine, human welfare.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "# Ethical Framework for AI Development\n",
      "\n",
      "I believe an ethical framework for AI should balance several key principles:\n",
      "\n",
      "1. **Beneficence and non-maleficence** - AI should benefit humanity while minimizing harm\n",
      "2. **Justice and fairness** - Benefits and risks should be distributed equitably\n",
      "3. **Autonomy and human oversight** - Humans should maintain meaningful control\n",
      "4. **Transparency and explainability** - AI systems should be understandable\n",
      "5. **Privacy and data rights** - Personal information should be protected\n",
      "\n",
      "For stakeholder prioritization, I'd suggest a balanced approach where:\n",
      "\n",
      "The wellbeing of the public, especially vulnerable populations, should receive primary consideration. Developer interests in innovation matter significantly but shouldn't override safety. Regulatory bodies serve as essential mediators.\n",
      "\n",
      "The most challenging ethical questions often emerge where these interests conflict—like when rapid innovation might bring both benefits and risks. In these cases, I think transparent, inclusive governance processes are crucial, where diverse voices help shape how we proceed with AI development.\n",
      "\n",
      "What aspects of AI ethics are you most concerned about?\n",
      "\n",
      "# Response from competitor 3\n",
      "\n",
      "The ethical framework governing the development and deployment of AI needs to be multi-faceted, balancing innovation with societal risk by focusing on **human flourishing, fairness, accountability, transparency, and sustainability.**\n",
      "\n",
      "Here's a breakdown of the proposed framework and how it prioritizes stakeholders:\n",
      "\n",
      "**I. The Ethical Framework (FOCUS):**\n",
      "\n",
      "*   **F**airness & Justice:\n",
      "    *   **Goal:**  Ensure equitable access to AI benefits and mitigate bias to prevent discrimination.\n",
      "    *   **Implementation:** Rigorous testing for bias across diverse datasets.  Explainable AI (XAI) techniques to understand decision-making.  Robust auditing processes.  Focus on representing diverse perspectives in AI design and development teams.\n",
      "*   **O**utcomes Focused:\n",
      "    *   **Goal:** Prioritize beneficial and desirable outcomes for humanity and the planet.\n",
      "    *   **Implementation:** Conduct thorough impact assessments prior to deployment.  Develop AI systems aligned with the UN Sustainable Development Goals and other agreed-upon societal priorities.  Embrace a value-sensitive design approach from the outset.\n",
      "*   **C**ontrol & Accountability:\n",
      "    *   **Goal:** Define clear lines of responsibility for AI systems' actions and ensure human oversight where necessary.\n",
      "    *   **Implementation:**  Establish clear accountability frameworks for developers, deployers, and users of AI.  Implement robust error handling and fail-safe mechanisms.  Require human-in-the-loop decision-making for high-stakes applications (e.g., healthcare, criminal justice). Implement red teaming to uncover potential vulnerabilities.\n",
      "*   **U**nderstanding & Transparency:\n",
      "    *   **Goal:** Promote understanding of how AI systems work and make decisions.\n",
      "    *   **Implementation:**  Develop explainable AI (XAI) techniques to make AI decision-making more transparent.  Ensure clear communication to users about the capabilities and limitations of AI systems.  Promote open-source AI development where feasible. Establish processes for users to understand the rationales behind AI decisions affecting them.\n",
      "*   **S**ustainability & Responsibility:\n",
      "    *   **Goal:** Consider the long-term environmental and societal impact of AI development.\n",
      "    *   **Implementation:**  Promote energy-efficient AI models and hardware.  Consider the impact on employment and skills development.  Address potential misuse of AI for malicious purposes (e.g., deepfakes, autonomous weapons). Implement AI safety research focused on avoiding unintended consequences.  Promote responsible data management and privacy.\n",
      "\n",
      "**II. Stakeholder Prioritization & Balancing:**\n",
      "\n",
      "Prioritization is complex, as the interests of stakeholders often overlap and conflict.  A successful framework must strive for a **delicate balance**, emphasizing certain principles based on the specific context.  Here's a broad overview:\n",
      "\n",
      "1.  **Individuals & Vulnerable Groups (Highest Priority in Many Cases):**\n",
      "    *   **Interests:**  Safety, well-being, autonomy, dignity, privacy, fairness, access to opportunities.\n",
      "    *   **Prioritization:** Protection from harm (physical, psychological, economic), equitable access to AI benefits, clear recourse mechanisms when harmed by AI systems, and the right to be informed about AI interactions. Prioritize applications of AI which benefit vulnerable groups.\n",
      "    *   **Balancing:** Must be balanced against the needs of public safety and national security.\n",
      "2.  **The Public (High Priority):**\n",
      "    *   **Interests:**  Societal benefit, public safety, economic growth, democratic values, environmental sustainability.\n",
      "    *   **Prioritization:** AI development should align with broader societal goals.  Public awareness and education about AI.  Democratic oversight of AI development and deployment.  Regulation to prevent harm and promote responsible innovation.\n",
      "    *   **Balancing:**  Must be balanced against the rights of individuals and the need for innovation.\n",
      "3.  **Researchers & Developers (Important):**\n",
      "    *   **Interests:**  Academic freedom, innovation, economic opportunity, recognition for their work.\n",
      "    *   **Prioritization:**  Support for basic AI research.  Access to data and resources.  Clear ethical guidelines and regulatory frameworks.  Protection of intellectual property.\n",
      "    *   **Balancing:** Must be balanced against the need for public safety and ethical considerations. Incentivize development of AI systems which align with the framework’s goals.\n",
      "4.  **Businesses & Organizations (Important):**\n",
      "    *   **Interests:**  Profitability, efficiency, competitive advantage, innovation.\n",
      "    *   **Prioritization:**  Clear regulatory frameworks.  Access to talent and resources.  Support for innovation.\n",
      "    *   **Balancing:**  Must be balanced against the need for societal benefit, fairness, and environmental sustainability. Businesses should be incentivized to incorporate ethical considerations into their AI development processes.\n",
      "5.  **Governments & Regulators (Essential):**\n",
      "    *   **Interests:**  National security, economic growth, public safety, social order, democratic governance.\n",
      "    *   **Prioritization:**  Developing and enforcing ethical guidelines and regulations.  Investing in AI research and development.  Promoting public awareness and education.  International cooperation.\n",
      "    *   **Balancing:** Must be balanced against the need for individual freedoms, innovation, and economic growth.\n",
      "\n",
      "**III. Key Considerations for Implementation:**\n",
      "\n",
      "*   **Context-Specificity:** The framework should be adaptable to different contexts and applications.\n",
      "*   **Continuous Monitoring & Evaluation:**  The framework should be regularly reviewed and updated to reflect advances in AI technology and societal values.\n",
      "*   **Multi-Stakeholder Engagement:** The development and implementation of the framework should involve representatives from all relevant stakeholder groups.\n",
      "*   **International Cooperation:** Given the global nature of AI, international cooperation is essential to ensure consistency and avoid regulatory fragmentation.\n",
      "*   **Education and Training:** Widespread education and training on AI ethics and responsible AI development are crucial for fostering a culture of ethical AI.\n",
      "*   **Redress Mechanisms:** Effective mechanisms for redress and accountability must be available to individuals and groups harmed by AI systems.\n",
      "*   **Regulation and Soft Law:** Combine regulatory oversight with industry self-regulation, standards development, and ethical codes of conduct.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "This proposed ethical framework, \"FOCUS,\" provides a foundation for navigating the complex ethical challenges of AI. By prioritizing fairness, focusing on beneficial outcomes, ensuring accountability, promoting transparency, and emphasizing sustainability, we can harness the transformative potential of AI while mitigating its risks and ensuring a future where AI benefits all of humanity. The key lies in continuous dialogue, adaptation, and a commitment to prioritizing human values in the age of AI.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = f\"\"\"You are judging a competition between {len(competitors)} competitors.\n",
    "Each model has been given this question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
    "Respond with JSON, and only JSON, with the following format:\n",
    "{{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}}\n",
    "\n",
    "Here are the responses from each competitor:\n",
    "\n",
    "{together}\n",
    "\n",
    "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT\n",
    "1. **When using f strings and you want to define a variable that requires curly braces but you also want to include the curly brace in the prompt, you need to nest curly brace in another curly brace, as follows:**\n",
    "\n",
    "```\n",
    "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
    "Respond with JSON, and only JSON, with the following format:\n",
    "{{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}}\n",
    "```\n",
    "\n",
    "2. **This prompt instruction is key when specifying JSON output:** *Do not include markdown formatting or code blocks.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are judging a competition between 3 competitors.\n",
      "Each model has been given this question:\n",
      "\n",
      "In a world where artificial intelligence continues to evolve and integrate into daily life, what ethical framework should govern the development and deployment of AI systems to balance innovation with societal risk, and how would you prioritize the interests of different stakeholders involved?\n",
      "\n",
      "Your job is to evaluate each response for clarity and strength of argument, and rank them in order of best to worst.\n",
      "Respond with JSON, and only JSON, with the following format:\n",
      "{\"results\": [\"best competitor number\", \"second best competitor number\", \"third best competitor number\", ...]}\n",
      "\n",
      "Here are the responses from each competitor:\n",
      "\n",
      "# Response from competitor 1\n",
      "\n",
      "In a rapidly advancing technological landscape, establishing an ethical framework for the development and deployment of AI systems is crucial for balancing innovation with societal risks. An effective framework should encompass a combination of principles that prioritize safety, fairness, accountability, transparency, and inclusivity. Here’s a detailed breakdown of how such a framework could be structured and how to prioritize stakeholder interests:\n",
      "\n",
      "### Ethical Framework Components\n",
      "\n",
      "1. **Safety and Security**:\n",
      "   - **Principle**: Ensure that AI systems are designed and rigorously tested to operate safely and securely, minimizing risks to human life and well-being.\n",
      "   - **Implementation**: Mandate safety protocols, continuous monitoring, and the use of best practices in AI development.\n",
      "\n",
      "2. **Fairness and Non-discrimination**:\n",
      "   - **Principle**: Strive for equitable outcomes, preventing biases against any individual or group.\n",
      "   - **Implementation**: Develop algorithms that are tested for bias and subjected to diverse input during both training and evaluation phases.\n",
      "\n",
      "3. **Transparency**:\n",
      "   - **Principle**: Allow stakeholders to understand how AI systems operate and make decisions.\n",
      "   - **Implementation**: Require clear documentation of AI models, decision-making processes, and potential limitations so that users and developers are fully informed.\n",
      "\n",
      "4. **Accountability**:\n",
      "   - **Principle**: Ensure that AI developers and organizations are responsible for the impacts of their technologies.\n",
      "   - **Implementation**: Establish governance structures that include compliance with regulatory standards, ethical reviews, and mechanisms for redress.\n",
      "\n",
      "5. **Inclusivity and Stakeholder Engagement**:\n",
      "   - **Principle**: Engage a diverse range of stakeholders in the development process to understand various perspectives and needs.\n",
      "   - **Implementation**: Foster dialogue with communities affected by AI implementation, considering their input throughout the development lifecycle.\n",
      "\n",
      "6. **Sustainability**:\n",
      "   - **Principle**: Consider the environmental impact of AI technologies and implement practices that promote sustainability.\n",
      "   - **Implementation**: Encourage the development of energy-efficient AI systems and promote technologies that solve real-world problems.\n",
      "\n",
      "### Prioritizing Stakeholder Interests\n",
      "\n",
      "The interests of different stakeholders (users, developers, organizations, regulators, and society at large) can be prioritized through a balanced approach:\n",
      "\n",
      "1. **Users**: Their safety, privacy, and empowerment should be the top priority. They should have access to information about how AI affects their lives and the ability to opt out of systems that do not prioritize their interests.\n",
      "\n",
      "2. **Developers and Organizations**: While innovation and profit motives are important, these must not undermine ethical considerations. Organizations should cultivate a culture of responsibility where ethical practice is integral to business models and not just an afterthought.\n",
      "\n",
      "3. **Regulators and Policymakers**: They should establish clear guidelines and frameworks that ensure ethical AI practices are followed. This includes setting standards for accountability and transparency, as well as inspecting compliance.\n",
      "\n",
      "4. **Society at Large**: Long-term societal impacts should be a crucial consideration. Initiatives should focus on ensuring that AI serves the public good and promotes social welfare, addressing regulatory needs that prioritize collective interests over individual profit.\n",
      "\n",
      "5. **Vulnerable Populations**: Special attention should be given to marginalized and vulnerable groups who might be disproportionately affected by AI technologies. They should have representation in decision-making processes and included in impact assessments.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "The proposed ethical framework for AI development and deployment emphasizes the need for a comprehensive approach that balances the interests of all stakeholders involved. By placing a strong emphasis on safety, fairness, transparency, and accountability, and by actively engaging diverse voices, we can foster an environment where innovation flourishes while safeguarding societal values and minimizing risks. Implementing such a framework can help ensure that AI technologies contribute positively to society and enhance, rather than undermine, human welfare.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "# Ethical Framework for AI Development\n",
      "\n",
      "I believe an ethical framework for AI should balance several key principles:\n",
      "\n",
      "1. **Beneficence and non-maleficence** - AI should benefit humanity while minimizing harm\n",
      "2. **Justice and fairness** - Benefits and risks should be distributed equitably\n",
      "3. **Autonomy and human oversight** - Humans should maintain meaningful control\n",
      "4. **Transparency and explainability** - AI systems should be understandable\n",
      "5. **Privacy and data rights** - Personal information should be protected\n",
      "\n",
      "For stakeholder prioritization, I'd suggest a balanced approach where:\n",
      "\n",
      "The wellbeing of the public, especially vulnerable populations, should receive primary consideration. Developer interests in innovation matter significantly but shouldn't override safety. Regulatory bodies serve as essential mediators.\n",
      "\n",
      "The most challenging ethical questions often emerge where these interests conflict—like when rapid innovation might bring both benefits and risks. In these cases, I think transparent, inclusive governance processes are crucial, where diverse voices help shape how we proceed with AI development.\n",
      "\n",
      "What aspects of AI ethics are you most concerned about?\n",
      "\n",
      "# Response from competitor 3\n",
      "\n",
      "The ethical framework governing the development and deployment of AI needs to be multi-faceted, balancing innovation with societal risk by focusing on **human flourishing, fairness, accountability, transparency, and sustainability.**\n",
      "\n",
      "Here's a breakdown of the proposed framework and how it prioritizes stakeholders:\n",
      "\n",
      "**I. The Ethical Framework (FOCUS):**\n",
      "\n",
      "*   **F**airness & Justice:\n",
      "    *   **Goal:**  Ensure equitable access to AI benefits and mitigate bias to prevent discrimination.\n",
      "    *   **Implementation:** Rigorous testing for bias across diverse datasets.  Explainable AI (XAI) techniques to understand decision-making.  Robust auditing processes.  Focus on representing diverse perspectives in AI design and development teams.\n",
      "*   **O**utcomes Focused:\n",
      "    *   **Goal:** Prioritize beneficial and desirable outcomes for humanity and the planet.\n",
      "    *   **Implementation:** Conduct thorough impact assessments prior to deployment.  Develop AI systems aligned with the UN Sustainable Development Goals and other agreed-upon societal priorities.  Embrace a value-sensitive design approach from the outset.\n",
      "*   **C**ontrol & Accountability:\n",
      "    *   **Goal:** Define clear lines of responsibility for AI systems' actions and ensure human oversight where necessary.\n",
      "    *   **Implementation:**  Establish clear accountability frameworks for developers, deployers, and users of AI.  Implement robust error handling and fail-safe mechanisms.  Require human-in-the-loop decision-making for high-stakes applications (e.g., healthcare, criminal justice). Implement red teaming to uncover potential vulnerabilities.\n",
      "*   **U**nderstanding & Transparency:\n",
      "    *   **Goal:** Promote understanding of how AI systems work and make decisions.\n",
      "    *   **Implementation:**  Develop explainable AI (XAI) techniques to make AI decision-making more transparent.  Ensure clear communication to users about the capabilities and limitations of AI systems.  Promote open-source AI development where feasible. Establish processes for users to understand the rationales behind AI decisions affecting them.\n",
      "*   **S**ustainability & Responsibility:\n",
      "    *   **Goal:** Consider the long-term environmental and societal impact of AI development.\n",
      "    *   **Implementation:**  Promote energy-efficient AI models and hardware.  Consider the impact on employment and skills development.  Address potential misuse of AI for malicious purposes (e.g., deepfakes, autonomous weapons). Implement AI safety research focused on avoiding unintended consequences.  Promote responsible data management and privacy.\n",
      "\n",
      "**II. Stakeholder Prioritization & Balancing:**\n",
      "\n",
      "Prioritization is complex, as the interests of stakeholders often overlap and conflict.  A successful framework must strive for a **delicate balance**, emphasizing certain principles based on the specific context.  Here's a broad overview:\n",
      "\n",
      "1.  **Individuals & Vulnerable Groups (Highest Priority in Many Cases):**\n",
      "    *   **Interests:**  Safety, well-being, autonomy, dignity, privacy, fairness, access to opportunities.\n",
      "    *   **Prioritization:** Protection from harm (physical, psychological, economic), equitable access to AI benefits, clear recourse mechanisms when harmed by AI systems, and the right to be informed about AI interactions. Prioritize applications of AI which benefit vulnerable groups.\n",
      "    *   **Balancing:** Must be balanced against the needs of public safety and national security.\n",
      "2.  **The Public (High Priority):**\n",
      "    *   **Interests:**  Societal benefit, public safety, economic growth, democratic values, environmental sustainability.\n",
      "    *   **Prioritization:** AI development should align with broader societal goals.  Public awareness and education about AI.  Democratic oversight of AI development and deployment.  Regulation to prevent harm and promote responsible innovation.\n",
      "    *   **Balancing:**  Must be balanced against the rights of individuals and the need for innovation.\n",
      "3.  **Researchers & Developers (Important):**\n",
      "    *   **Interests:**  Academic freedom, innovation, economic opportunity, recognition for their work.\n",
      "    *   **Prioritization:**  Support for basic AI research.  Access to data and resources.  Clear ethical guidelines and regulatory frameworks.  Protection of intellectual property.\n",
      "    *   **Balancing:** Must be balanced against the need for public safety and ethical considerations. Incentivize development of AI systems which align with the framework’s goals.\n",
      "4.  **Businesses & Organizations (Important):**\n",
      "    *   **Interests:**  Profitability, efficiency, competitive advantage, innovation.\n",
      "    *   **Prioritization:**  Clear regulatory frameworks.  Access to talent and resources.  Support for innovation.\n",
      "    *   **Balancing:**  Must be balanced against the need for societal benefit, fairness, and environmental sustainability. Businesses should be incentivized to incorporate ethical considerations into their AI development processes.\n",
      "5.  **Governments & Regulators (Essential):**\n",
      "    *   **Interests:**  National security, economic growth, public safety, social order, democratic governance.\n",
      "    *   **Prioritization:**  Developing and enforcing ethical guidelines and regulations.  Investing in AI research and development.  Promoting public awareness and education.  International cooperation.\n",
      "    *   **Balancing:** Must be balanced against the need for individual freedoms, innovation, and economic growth.\n",
      "\n",
      "**III. Key Considerations for Implementation:**\n",
      "\n",
      "*   **Context-Specificity:** The framework should be adaptable to different contexts and applications.\n",
      "*   **Continuous Monitoring & Evaluation:**  The framework should be regularly reviewed and updated to reflect advances in AI technology and societal values.\n",
      "*   **Multi-Stakeholder Engagement:** The development and implementation of the framework should involve representatives from all relevant stakeholder groups.\n",
      "*   **International Cooperation:** Given the global nature of AI, international cooperation is essential to ensure consistency and avoid regulatory fragmentation.\n",
      "*   **Education and Training:** Widespread education and training on AI ethics and responsible AI development are crucial for fostering a culture of ethical AI.\n",
      "*   **Redress Mechanisms:** Effective mechanisms for redress and accountability must be available to individuals and groups harmed by AI systems.\n",
      "*   **Regulation and Soft Law:** Combine regulatory oversight with industry self-regulation, standards development, and ethical codes of conduct.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "This proposed ethical framework, \"FOCUS,\" provides a foundation for navigating the complex ethical challenges of AI. By prioritizing fairness, focusing on beneficial outcomes, ensuring accountability, promoting transparency, and emphasizing sustainability, we can harness the transformative potential of AI while mitigating its risks and ensuring a future where AI benefits all of humanity. The key lies in continuous dialogue, adaptation, and a commitment to prioritizing human values in the age of AI.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\n"
     ]
    }
   ],
   "source": [
    "print(judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_messages = [{\"role\": \"user\", \"content\": judge}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"results\": [\"3\", \"1\", \"2\"]}\n"
     ]
    }
   ],
   "source": [
    "# Judgement time!\n",
    "\n",
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"o3-mini\",\n",
    "    messages=judge_messages,\n",
    ")\n",
    "results = response.choices[0].message.content\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: gemini-2.0-flash\n",
      "Rank 2: gpt-4o-mini\n",
      "Rank 3: claude-3-7-sonnet-latest\n"
     ]
    }
   ],
   "source": [
    "# OK let's turn this into results!\n",
    "\n",
    "results_dict = json.loads(results)\n",
    "ranks = results_dict[\"results\"]\n",
    "for index, result in enumerate(ranks):\n",
    "    competitor = competitors[int(result)-1]\n",
    "    print(f\"Rank {index+1}: {competitor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"results\": [\"3\", \"1\", \"2\"]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# try gemini as the judge\n",
    "\n",
    "gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "model_name = \"gemini-2.0-flash\"\n",
    "\n",
    "response = gemini.chat.completions.create(model=model_name, messages=judge_messages)\n",
    "gemini_results = response.choices[0].message.content\n",
    "\n",
    "print(gemini_results)\n",
    "\n",
    "# openai = OpenAI()\n",
    "# response = openai.chat.completions.create(\n",
    "#     model=\"o3-mini\",\n",
    "#     messages=judge_messages,\n",
    "# )\n",
    "# results = response.choices[0].message.content\n",
    "# print(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Which pattern(s) did this use? Try updating this to add another Agentic design pattern.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt chaining followed by Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Commercial implications</h2>\n",
    "            <span style=\"color:#00bfff;\">These kinds of patterns - to send a task to multiple models, and evaluate results,\n",
    "            are common where you need to improve the quality of your LLM response. This approach can be universally applied\n",
    "            to business projects where accuracy is critical.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Before I started this course, I thought of using the evaluator strategy to check the accuracy of a translation. I hadn't started coding it, but I realized that I should use another LLM to check the translation performance of a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lesson showed how to use dictionaries to store multiple responses that can then be compared later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, importantly, the comparator-evaluator aspect used JSON to report out exact/specific desired output that you wish to collect. I hadn't thought of specifying JSON output for handling and categorizing responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
