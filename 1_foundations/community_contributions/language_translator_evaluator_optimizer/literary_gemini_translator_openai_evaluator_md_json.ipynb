{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3091323f-9b5c-4b67-a397-4a646d55e41c",
   "metadata": {},
   "source": [
    "**LLM Translation with Evaluator Proofreading (Markdown version)**    \n",
    "Using code created by Ed Donner in his Udemy Agentic AI course  \n",
    "*Translator: Gemini model*  \n",
    "*Evaluator: OpenAI model*  \n",
    "\n",
    "George MacDonald's [***The Princess and the Goblin***](https://github.com/mlschmitt/classic-books-markdown/blob/main/George%20MacDonald/The%20Princess%20and%20the%20Goblin.md) markdown file available from [**Michael Schmitt**](https://github.com/mlschmitt)'s [**classic-books-markdown**](https://github.com/mlschmitt/classic-books-markdown) repo on GitHub. \n",
    "\n",
    "For a brief overview and background, visit [**LLM Language Translation Tools**](https://github.com/shandran/llm_translation_tools/tree/main) page on my GitHub repo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a992e9b2-79a5-48ce-87f9-243a2653b231",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ee7bed-3477-4520-ac75-2d1b1fa3a8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "import google.generativeai as genai\n",
    "from IPython.display import Markdown, display\n",
    "from docx import Document\n",
    "import re\n",
    "import tiktoken\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from openai import NotFoundError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f04c8b-3e6a-43fc-a9a3-1d24839a9a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load API keys\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50bcc87-4f0c-4a1f-91ae-7d70a1d6c103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the key prefixes to help with any debugging\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "genai.configure(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abae4ec-a458-4a2c-b69a-a98fb6ed2bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM model to use\n",
    "openai_model =  'gpt-4o' # 'o3-2025-04-16' # For better quality but higher cost: 'o3-2025-04-16' # 200K context window 100K max output tokens $2/$8\n",
    "gemini_model = 'gemini-2.5-flash' # gemini-2.5-pro' # 1M context window 65K max output tokens $1.25/$10 <200K $2.50/$15 >=200K tokens \n",
    "claude_model = 'claude-sonnet-4-0' # 200K context window 65K max output tokens $3/$15\n",
    "\n",
    "openai = OpenAI()\n",
    "claude = Anthropic()\n",
    "gemini = genai.GenerativeModel(model_name=gemini_model)\n",
    "\n",
    "# define languages\n",
    "source_language = 'English'\n",
    "translated_language = 'Traditional Chinese'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9670ff3-5288-4096-915a-07b8b6f71562",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Gemini model: {gemini_model}\")\n",
    "print(f\"OpenAI model: {openai_model}\")\n",
    "print(f\"Claude model: {claude_model}\")\n",
    "print(f\"Translation language: {translated_language}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d53a135-d596-41a2-ac5c-1864ef811e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open md document with source material\n",
    "filename = \"George_MacDonald_The_Princess_and_the_Goblin_50_lines.md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74b9726-ffc4-4245-9af5-84e39d5899bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the markdown file\n",
    "with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Set up tokenizer (GPT-4-compatible)\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4\")  # or \"gpt-4o\" if preferred\n",
    "\n",
    "# ---------- Structure Detection Helpers ----------\n",
    "def is_heading(line):\n",
    "    return re.match(r\"^#{1,6} \", line)\n",
    "\n",
    "def is_list_item(line):\n",
    "    return re.match(r\"^(\\s*[-*+] |\\s*\\d+\\.\\s)\", line)\n",
    "\n",
    "def is_blockquote(line):\n",
    "    return line.strip().startswith(\">\")\n",
    "\n",
    "def is_code_fence(line):\n",
    "    # This regex looks for lines that start with at least three backticks\n",
    "    # and optionally include language specifiers. It also handles closing fences.\n",
    "    return re.match(r\"^\\s*`{3,}\", line)\n",
    "\n",
    "def is_blank(line):\n",
    "    return line.strip() == \"\"\n",
    "\n",
    "# ---------- Group Lines into Logical Blocks ----------\n",
    "blocks = []\n",
    "current_block = []\n",
    "in_code_block = False\n",
    "in_blockquote_block = False # New flag for blockquote\n",
    "\n",
    "for line in lines:\n",
    "    if is_code_fence(line):\n",
    "        # If exiting a blockquote before a code fence, close it out\n",
    "        if in_blockquote_block and current_block:\n",
    "            blocks.append(\"\".join(current_block).strip())\n",
    "            current_block = []\n",
    "            in_blockquote_block = False\n",
    "\n",
    "        in_code_block = not in_code_block\n",
    "        current_block.append(line)\n",
    "        if not in_code_block: # If just closed a code block\n",
    "            blocks.append(\"\".join(current_block).strip())\n",
    "            current_block = []\n",
    "        continue # Move to next line, as code fence handled itself\n",
    "\n",
    "    if in_code_block: # If currently inside a code block\n",
    "        current_block.append(line)\n",
    "        continue\n",
    "\n",
    "    # Handle blockquotes\n",
    "    if is_blockquote(line):\n",
    "        if not in_blockquote_block: # If starting a new blockquote block\n",
    "            if current_block: # If there's a preceding block of different type\n",
    "                blocks.append(\"\".join(current_block).strip())\n",
    "                current_block = []\n",
    "            in_blockquote_block = True\n",
    "        current_block.append(line) # Always append blockquote lines to current_block\n",
    "    else: # Not a blockquote line\n",
    "        if in_blockquote_block: # If exiting a blockquote block\n",
    "            if current_block: # Ensure there's content to append\n",
    "                blocks.append(\"\".join(current_block).strip())\n",
    "                current_block = []\n",
    "            in_blockquote_block = False # Reset the flag\n",
    "\n",
    "        # Handle other block types outside of blockquote logic\n",
    "        if is_heading(line) or is_list_item(line):\n",
    "            if current_block: # If there's a preceding block of different type\n",
    "                blocks.append(\"\".join(current_block).strip())\n",
    "                current_block = []\n",
    "            current_block.append(line)\n",
    "        elif is_blank(line):\n",
    "            if current_block: # If there's content to append before a blank line\n",
    "                blocks.append(\"\".join(current_block).strip())\n",
    "                current_block = []\n",
    "            # Do not append blank lines themselves as blocks, they act as separators\n",
    "        else: # Regular paragraph text\n",
    "            current_block.append(line)\n",
    "\n",
    "# Add any remaining content in current_block as a final block\n",
    "if current_block:\n",
    "    blocks.append(\"\".join(current_block).strip())\n",
    "\n",
    "# ---------- Group Blocks into Token-Aware Chunks ----------\n",
    "target_tokens = 300 # 150\n",
    "max_tokens = 400 # 180 # Not explicitly used for dynamic splitting in this structure, but good for upper bound\n",
    "chunks = []\n",
    "current_chunk = []\n",
    "current_token_count = 0\n",
    "chunk_id = 1\n",
    "\n",
    "for block in blocks:\n",
    "    block_tokens = len(enc.encode(block))\n",
    "\n",
    "    # If adding the current block exceeds the target and there's already content in the current chunk\n",
    "    # then finalize the current chunk and start a new one.\n",
    "    if current_token_count + block_tokens > target_tokens and current_chunk:\n",
    "        chunk_text = \"\\n\\n\".join(current_chunk) # This is where blocks are joined\n",
    "        chunks.append({\n",
    "            \"chunk_id\": chunk_id,\n",
    "            \"tokens\": current_token_count,\n",
    "            \"text\": chunk_text\n",
    "        })\n",
    "        chunk_id += 1\n",
    "        current_chunk = []\n",
    "        current_token_count = 0\n",
    "\n",
    "    current_chunk.append(block)\n",
    "    current_token_count += block_tokens\n",
    "\n",
    "# Add final chunk if there's any remaining content\n",
    "if current_chunk:\n",
    "    chunk_text = \"\\n\\n\".join(current_chunk)\n",
    "    chunks.append({\n",
    "        \"chunk_id\": chunk_id,\n",
    "        \"tokens\": current_token_count,\n",
    "        \"text\": chunk_text\n",
    "    })\n",
    "\n",
    "# ---------- Optional: Save as JSON ----------\n",
    "output_json_filename = \"markdown_chunks.json\"\n",
    "with open(output_json_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(chunks, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# ---------- Preview ----------\n",
    "for chunk in chunks:\n",
    "    # Print only the first 300 characters for preview to avoid large output\n",
    "    print(f\"\\n--- Chunk {chunk['chunk_id']} ({chunk['tokens']} tokens) of {len(chunks)} ---\\n{chunk['text'][:300]}{'...' if len(chunk['text']) > 300 else ''}\\n\")\n",
    "print(f\"\\n✅ {len(chunks)} chunks created and saved to '{output_json_filename}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7531e74-b2f4-42f2-93e3-16866bf5c0d7",
   "metadata": {},
   "source": [
    "### Translation prompt (system_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dcfdb2-f4bc-4722-86f6-6aabb1f43c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt instruction\n",
    "system_message = f\"\"\"\n",
    "You are a professional translator of classic literary works in English.\n",
    "Your task is to translate chunked markdown inputs (headings, paragraphs, blockquotes, lists, code blocks, etc.) from {source_language} into {translated_language}, preserving all original formatting and markdown syntax exactly.\n",
    "\n",
    "Requirements:\n",
    "1. Faithfully render every word and phrase; do NOT summarize, simplify, omit, or add commentary.\n",
    "2. Use vocabulary and idioms familiar to a general readership audience.\n",
    "3. Preserve all punctuation, inline code, and block structures.\n",
    "4. Maintain consistent translation approach across all chunks.\n",
    "5. Retain capitalization of proper names and headings exactly as in the source.\n",
    "6. Output only the translated markdown text: no explanations, no extra whitespace beyond what is in the input.\n",
    "\n",
    "Start each response with the translated chunk; do not include any metadata or system commentary.\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\": \"user\", \"content\": system_message}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a8c7c1-a9e8-4867-81a5-45011e91f221",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "system_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8877f7-04cf-4552-967c-d6867d8b44e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706b908f-ffbd-49a5-86f7-c20c22491def",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Gemini model: {gemini_model}\")\n",
    "print(f\"OpenAI model: {openai_model}\")\n",
    "print(f\"Claude model: {claude_model}\")\n",
    "print(f\"Translation language: {translated_language}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639fa2c4-eb53-4157-b3c8-47519abb496c",
   "metadata": {},
   "source": [
    "### Translation function (translate_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475888ef-2294-488e-bff8-1af8152f814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translator function with error reporting to 'error', handling empty returns, and a settable max retries \n",
    "\n",
    "def translate_chunk(\n",
    "    text: str,\n",
    "    system_message: str,\n",
    "    idx: int = None,\n",
    "    total: int = None,\n",
    "    retry_on_rate_limit: bool = True\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Sends one chunk of text through Gemini and returns the translated string.\n",
    "    Retries once on exceptions or empty responses, and records errors in chunk['error'].\n",
    "    If both the initial call and retry fail, returns the sentinel \"translation failed\".\n",
    "    \"\"\"\n",
    "    if idx is not None and total is not None:\n",
    "        print(\n",
    "            f\"Translating chunk {idx}/{total} \"\n",
    "            f\"(first 50 chars): {text[:50]}... | Type: {type(text)}\"\n",
    "        )\n",
    "   \n",
    "    prompt = system_message + \"\\n\\n\" + text\n",
    "    attempt = 0\n",
    "    MAX_RETRIES = 1\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            response = gemini.generate_content(\n",
    "                contents=[{\"role\": \"user\", \"parts\": [prompt]}]\n",
    "            )\n",
    "            out = response.text.strip()\n",
    "            if not out:\n",
    "                # treat empty response as an error\n",
    "                raise ValueError(\"Empty response from Gemini\")\n",
    "            return out\n",
    "\n",
    "        except Exception as e:\n",
    "            attempt += 1\n",
    "            print(f\"⚠️  Translation error on chunk {idx}: {e}\")\n",
    "            # record the error into the chunk dict if available\n",
    "            try:\n",
    "                chunk.setdefault('error', str(e))\n",
    "            except NameError:\n",
    "                pass  # chunk not in scope here\n",
    "\n",
    "            if not retry_on_rate_limit or attempt > MAX_RETRIES:\n",
    "                print(f\"‼️  Translation failed for chunk {idx}, moving on.\")\n",
    "                return \"translation failed\"\n",
    "\n",
    "            print(\"…retrying after brief pause…\")\n",
    "            time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82cb085-2110-4ac5-b925-db25066bcc55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffe2189d-334b-4e1b-9f45-f17a19005878",
   "metadata": {},
   "source": [
    "### Call translation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f2c1b7-ee2b-408f-abec-e67bacbabf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the master timer\n",
    "master_start = time.perf_counter()\n",
    "\n",
    "for i, chunk in enumerate(chunks, start=1):\n",
    "    chunk['error'] = None\n",
    "    translated = translate_chunk(\n",
    "        chunk['text'],\n",
    "        system_message,\n",
    "        idx=i,\n",
    "        total=len(chunks),\n",
    "        retry_on_rate_limit=True\n",
    "    )\n",
    "    chunk['check'] = translated\n",
    "    print(f\"✅ Updated chunk_id {chunk['chunk_id']}\\n\")\n",
    "\n",
    "# Stop the master timer and report H:M:S\n",
    "master_end = time.perf_counter()\n",
    "total_seconds = master_end - master_start\n",
    "hours   = int(total_seconds // 3600)\n",
    "minutes = int((total_seconds % 3600) // 60)\n",
    "seconds = total_seconds % 60\n",
    "\n",
    "print(\n",
    "    f\"⏱️ Total processing time: \"\n",
    "    f\"{hours}h {minutes}m {seconds:.2f}s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8772f70e-556c-40a0-81c5-a791660163d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82505508-b529-453f-8569-26a0dfee0f4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chunks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad608416-0c9c-493e-93ce-0866454cdd05",
   "metadata": {},
   "source": [
    "#### Check for errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384093dc-a85b-420b-a485-f1b657c92951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify and display error entries\n",
    "errors = [chunk for chunk in chunks if chunk.get('error')]\n",
    "\n",
    "# Count\n",
    "eno_error = len([c for c in chunks if c.get('error') is None])\n",
    "has_error = len(errors)\n",
    "print(f\"No error: {eno_error}, With error: {has_error}\")\n",
    "\n",
    "# Pretty-print error chunks\n",
    "print(\"Chunks containing errors:\")\n",
    "print(json.dumps(errors, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbba164-1948-4ab5-8774-3096b4d7f756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81c57cf-0854-45e8-bcca-a77d3d9e2841",
   "metadata": {},
   "source": [
    "### Evaluation function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d806377b-1573-4caf-8bb9-1da6081418ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_chunk(\n",
    "    chunk: dict,\n",
    "    system_message: str,\n",
    "    source_language: str,\n",
    "    translated_language: str,\n",
    "    translate_func,\n",
    "    idx: int = None,\n",
    "    total: int = None,\n",
    "    retry_on_failure: bool = True\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    1) Runs primary evaluation on chunk['check'] and records chunk['primary_feedback'].\n",
    "    2) If passed, sets chunk['final']=chunk['check'], chunk['final_model']=gemini_model.\n",
    "    3) If failed and retry_on_failure, translates with Claude, records chunk['alt_feedback'], re-evaluates once.\n",
    "    4) On fallback pass, sets chunk['final']=fallback text and chunk['final_model']=claude_model; if both fail, final_model=None.\n",
    "    Returns chunk['final'].\n",
    "    \"\"\"\n",
    "\n",
    "    def _call_evaluator(text_to_check: str):\n",
    "        # Build the evaluation prompt with localized name exceptions\n",
    "        evaluation_prompt = f\"\"\"\n",
    "You are a professional translation evaluator reviewing translated classic literary works for a general audience. \n",
    "Your task is to assess whether a translated markdown chunk faithfully and accurately follows the original, based on the following criteria:\n",
    "\n",
    "The input text is chunked and therefore may include partial or incomplete sentences. Do not reject the accuracy of the translation due to chunking issues.\n",
    "\n",
    "1. **Accuracy**: The meaning is faithfully preserved — no additions, omissions, or summarizations.\n",
    "2. **Contextual Fidelity**: Terms are rendered precisely and consistently.\n",
    "3. **Markdown Integrity**: All formatting (headings, lists, blockquotes, punctuation, verse references, etc.) is preserved exactly.\n",
    "4. **Audience Awareness**: Language attempts to translate idioms and style as best as feasible for a translated work.\n",
    "5. **Proper Names and Capitalization**: All names and headings match the source formatting, or uses standard, established equivalents in target lan\n",
    "\n",
    "Source:\n",
    "{chunk['text']}\n",
    "\n",
    "Translation:\n",
    "{text_to_check}\n",
    "\n",
    "Respond with ONLY raw JSON:\n",
    "{{\n",
    "  \"passed\": true or false,\n",
    "  \"feedback\": \"If failed, brief specific reason; empty if passed\"\n",
    "}}\n",
    "\"\"\".strip()\n",
    "\n",
    "        resp = openai.chat.completions.create(\n",
    "            model=openai_model,\n",
    "            messages=[{\"role\": \"user\", \"content\": evaluation_prompt}]\n",
    "        ).choices[0].message.content.strip()\n",
    "        clean = re.sub(r'^```(?:json)?\\r?\\n', '', resp)\n",
    "        clean = re.sub(r'\\r?\\n```$', '', clean)\n",
    "        return json.loads(clean)\n",
    "\n",
    "    # Primary evaluation\n",
    "    if idx and total:\n",
    "        print(f\"Evaluating chunk {idx}/{total} with {gemini_model}…\", end=\" \")\n",
    "    verdict = _call_evaluator(chunk['check'])\n",
    "    chunk['primary_feedback'] = verdict.get('feedback', \"\")\n",
    "    chunk['passed'] = verdict.get('passed', False)\n",
    "\n",
    "    if chunk['passed']:\n",
    "        chunk['final'] = chunk['check']\n",
    "        chunk['final_model'] = gemini_model\n",
    "        print(\"→ primary passed\")\n",
    "        return chunk['final']\n",
    "\n",
    "    # Fallback to Claude\n",
    "    chunk['alt_feedback'] = None\n",
    "    if retry_on_failure:\n",
    "        print(\"→ primary failed; translating with Claude…\")\n",
    "        claude_resp = claude.messages.create(\n",
    "                    model=claude_model,\n",
    "                    messages=[\n",
    "                        {\"role\": \"user\",   \"content\": system_message + \"\\n\\n\" + chunk[\"text\"]\n",
    "                        }\n",
    "                    ],\n",
    "                    max_tokens=1000\n",
    "                )\n",
    "        \n",
    "        alt_text = claude_resp.content[0].text\n",
    "        chunk['check_alt'] = alt_text\n",
    "\n",
    "        if idx and total:\n",
    "            print(f\"Re-evaluating chunk {idx}/{total} with {claude_model}…\", end=\" \")\n",
    "        verdict2 = _call_evaluator(alt_text)\n",
    "        chunk['alt_feedback'] = verdict2.get('feedback', \"\")\n",
    "        chunk['passed'] = verdict2.get('passed', False)\n",
    "\n",
    "        if chunk['passed']:\n",
    "            chunk['final'] = alt_text\n",
    "            chunk['final_model'] = claude_model\n",
    "            print(\"→ fallback passed\")\n",
    "            return chunk['final']\n",
    "\n",
    "    # Both failed\n",
    "    reason = chunk['alt_feedback'] or chunk['primary_feedback'] or 'Unknown reason'\n",
    "    chunk['final'] = (\n",
    "        f\"Translation into {translated_language} failed: {reason}\"\n",
    "    )\n",
    "    chunk['final_model'] = None\n",
    "    print(f\"→ both evaluations failed: {reason}\")\n",
    "    return chunk['final']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f697660-8512-44a1-b9c8-2e06d2c0f919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05b29e37-5417-413a-9ad9-58356bfbc65e",
   "metadata": {},
   "source": [
    "### Call the Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e227307-9849-4cfd-a9ba-0bab45af2294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Start the overall timer\n",
    "master_start = time.perf_counter()\n",
    "\n",
    "for idx, chunk in enumerate(chunks, start=1):\n",
    "    # Skip chunks already evaluated\n",
    "    if 'passed' in chunk and 'final_model' in chunk:\n",
    "        print(f\"--- Chunk {idx}/{len(chunks)} (ID: {chunk['chunk_id']}) already evaluated; skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Initialize evaluator-stage error field only\n",
    "    chunk['eval_error'] = None\n",
    "\n",
    "    print(f\"\\n--- Chunk {idx}/{len(chunks)} (ID: {chunk['chunk_id']}) ---\")\n",
    "    print(\"✅ Using existing translation; starting evaluation…\")\n",
    "\n",
    "    try:\n",
    "        # Call the unified evaluate_chunk (includes fallback)\n",
    "        final_text = evaluate_chunk(\n",
    "            chunk,\n",
    "            system_message,\n",
    "            source_language,\n",
    "            translated_language,\n",
    "            translate_chunk,\n",
    "            idx=idx,\n",
    "            total=len(chunks),\n",
    "            retry_on_failure=True\n",
    "        )\n",
    "        chunk['final'] = final_text\n",
    "    except Exception as e:\n",
    "        # Catch any unexpected errors in evaluation\n",
    "        chunk['eval_error'] = str(e)\n",
    "        chunk['final'] = f\"Evaluation error: {e}\"\n",
    "        chunk['final_model'] = None\n",
    "        print(f\"⚠️  Unexpected evaluation error on chunk {chunk['chunk_id']}: {e}\")\n",
    "\n",
    "    # Report outcome\n",
    "    if chunk['final'].startswith(\"Translation into\") or chunk['final'].startswith(\"Evaluation error\"):\n",
    "        print(f\"‼️  Chunk {chunk['chunk_id']} ultimately failed.\\n\")\n",
    "    else:\n",
    "        print(f\"🎉 Chunk {chunk['chunk_id']} passed! Saved to chunk['final'].\\n\")\n",
    "\n",
    "# 2) Stop the overall timer\n",
    "master_end = time.perf_counter()\n",
    "total_seconds = master_end - master_start\n",
    "hours = int(total_seconds // 3600)\n",
    "minutes = int((total_seconds % 3600) // 60)\n",
    "seconds = total_seconds % 60\n",
    "\n",
    "print(\n",
    "    f\"⏱️ Total evaluation time: {hours}h {minutes}m {seconds:.2f}s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0310e0-8906-4914-b252-e93e9025f9d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc27452-5ffa-4199-aff9-196372e0f2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdba103-483d-4ccc-82a2-eaede9bb6592",
   "metadata": {},
   "source": [
    "#### Pass-fail counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e59c692-dbd6-4e5e-88de-d1375f65d461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only include entries where 'passed' exists\n",
    "counts = Counter(c.get('passed') for c in chunks if 'passed' in c)\n",
    "print(f\"Passed: {counts[True]}, Failed: {counts[False]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83219ed-977e-4a26-a56a-517493870ecb",
   "metadata": {},
   "source": [
    "#### Print failed entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1734a437-c7b6-4b94-8c4f-73c4e29527a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Get only the entries where passed is False\n",
    "fails = [chunk for chunk in chunks if chunk.get('passed') is False]\n",
    "\n",
    "# 2) Dump them as nicely formatted JSON\n",
    "print(json.dumps(fails, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ec67f8-4d95-4c62-9db7-3b5d11b89288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2b0101b-9222-4ea8-b2a4-e1693be9cd03",
   "metadata": {},
   "source": [
    "### Token size distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c5ab46-e691-490f-9066-3d72c2f637cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract token counts\n",
    "tokens = [chunk['tokens'] for chunk in chunks]\n",
    "\n",
    "# Create histogram\n",
    "plt.figure()\n",
    "plt.hist(tokens, bins='auto')\n",
    "plt.title('Distribution of Chunk Token Counts')\n",
    "plt.xlabel('Token Count')\n",
    "plt.ylabel('Number of Chunks')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a471b4-b408-429d-a94a-21e0f48b4c13",
   "metadata": {},
   "source": [
    "# Clean up failed entries, if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f69aa4-6ec8-4a3d-a7bd-695c358e54ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Mini evaluator function (reuse existing prompt logic)\n",
    "def mini_evaluate(text_to_check: str, source_text: str) -> dict:\n",
    "    evaluation_prompt = f\"\"\"\n",
    "You are a professional translation evaluator reviewing translated Biblical education materials for a Protestant/Evangelical audience.\n",
    "Your task is to assess whether a translated markdown chunk faithfully and accurately follows the original, based on these criteria:\n",
    "\n",
    "1. **Accuracy**: Meaning is preserved—no additions, omissions, or summarizations.\n",
    "2. **Theological Fidelity**: Key theological terms are rendered precisely.\n",
    "3. **Markdown Integrity**: All headings, lists, blockquotes, punctuation, verse references must be preserved.\n",
    "4. **Audience Awareness**: Language reflects Protestant/Evangelical style and idioms.\n",
    "5. **Proper Names**: Preserve proper names exactly, except standard localized equivalents (e.g., Spanish Bible book titles).\n",
    "\n",
    "Source:\n",
    "{source_text}\n",
    "\n",
    "Translation:\n",
    "{text_to_check}\n",
    "\n",
    "Respond with ONLY raw JSON:\n",
    "{{\n",
    "  \"passed\": true or false,\n",
    "  \"feedback\": \"If failed, brief specific reason; empty if passed\"\n",
    "}}\n",
    "\"\"\".strip()\n",
    "\n",
    "    resp = openai.chat.completions.create(\n",
    "        model=openai_model,\n",
    "        messages=[{\"role\": \"user\", \"content\": evaluation_prompt}]\n",
    "    ).choices[0].message.content.strip()\n",
    "\n",
    "    clean = re.sub(r'^```(?:json)?\\r?\\n', '', resp)\n",
    "    clean = re.sub(r'\\r?\\n```$', '', clean)\n",
    "    return json.loads(clean)\n",
    "\n",
    "# Identify currently failing chunks\n",
    "fails = [chunk for chunk in chunks if not chunk.get('passed')]\n",
    "print(f\"🔄 Re-evaluating {len(fails)} initially failed chunks…\")\n",
    "start = time.perf_counter()\n",
    "\n",
    "for idx, chunk in enumerate(fails, start=1):\n",
    "    print(f\"→ [{idx}/{len(fails)}] Re-checking chunk_id {chunk['chunk_id']}…\")\n",
    "    verdict = mini_evaluate(chunk['check'], chunk['text'])\n",
    "    if verdict.get('passed'):\n",
    "        chunk['final'] = chunk['check']\n",
    "        chunk['final_model'] = gemini_model\n",
    "        print(f\"   ✅ chunk_id {chunk['chunk_id']} now passes primary re-check.\")\n",
    "    else:\n",
    "        print(f\"   ❌ chunk_id {chunk['chunk_id']} failed primary re-check: {verdict.get('feedback')}\\n   → Attempting Claude fallback…\")\n",
    "        # run Claude fallback\n",
    "        claude_resp = claude.messages.create(\n",
    "            model=claude_model,\n",
    "            messages=[\n",
    "                {\"role\": \"user\",   \"content\": system_message + \"\\n\\n\" + chunk[\"text\"]\n",
    "                }\n",
    "            ],\n",
    "            max_tokens=1000\n",
    "        )\n",
    "        alt_text = claude_resp.completion.strip()\n",
    "        chunk['check_alt'] = alt_text\n",
    "        # re-evaluate fallback\n",
    "        fallback_verdict = mini_evaluate(alt_text, chunk['text'])\n",
    "        if fallback_verdict.get('passed'):\n",
    "            chunk['final'] = alt_text\n",
    "            chunk['final_model'] = claude_model\n",
    "            print(f\"   ✅ chunk_id {chunk['chunk_id']} now passes with Claude fallback.\")\n",
    "        else:\n",
    "            print(f\"   ❌ chunk_id {chunk['chunk_id']} still fails fallback: {fallback_verdict.get('feedback')}\")\n",
    "\n",
    "end = time.perf_counter()\n",
    "elapsed = end - start\n",
    "hours = int(elapsed // 3600)\n",
    "minutes = int((elapsed % 3600) // 60)\n",
    "seconds = elapsed % 60\n",
    "print(f\"\\n⏱️ Total re-evaluation (with fallback) time: {hours}h {minutes}m {seconds:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859a10a8-a688-4b13-a1b6-cf2d814b423a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d8bf77-4678-4361-9ddd-92d41177bee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6581f8eb-831b-452e-8743-19c053a609a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# extract all final_model values (will include None if missing)\n",
    "models = [chunk.get('final_model') for chunk in chunks]\n",
    "\n",
    "# tabulate counts\n",
    "counts = Counter(models)\n",
    "\n",
    "print(counts)\n",
    "# e.g. Counter({'model_A': 123, 'model_B': 77, None: 5})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dedd04f-5c06-4d2e-8c2d-91e0088285f1",
   "metadata": {},
   "source": [
    "### Save json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a028279-fdbe-430f-bcbf-d855880fe5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the .md extension\n",
    "base = os.path.splitext(filename)[0]\n",
    "\n",
    "# remove spaces if any from output language\n",
    "output_language = translated_language.replace(\" \", \"\")\n",
    "\n",
    "# timestamp in yyyy-mm-dd-hhMMSS format\n",
    "ts = datetime.now().strftime(\"%Y-%m-%d-%H%M%S\")\n",
    "\n",
    "# build the output filename\n",
    "out_fname = f\"{base}_{output_language}_{gemini_model}_{openai_model}_{ts}.json\"\n",
    "\n",
    "# write to disk\n",
    "with open(out_fname, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(chunks, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"✅ Exported results to {out_fname}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043ea7cb-417d-4859-81b1-cd47bb53d4b5",
   "metadata": {},
   "source": [
    "### Create and save an interlinear markdown file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0db2ff-1e4c-43c3-8843-e8da5630bed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Turn your existing JSON filename into a .md filename\n",
    "base = os.path.splitext(out_fname)[0]\n",
    "markdown_fname = base + '_interlinear' + '.md'\n",
    "\n",
    "# 2) Write each chunk’s original + final translation into the .md\n",
    "with open(markdown_fname, \"w\", encoding=\"utf-8\") as md_file:\n",
    "    for chunk in chunks:\n",
    "        md_file.write(chunk['text'])\n",
    "        md_file.write(\"\\n\\n\")\n",
    "        md_file.write(chunk.get('final', ''))\n",
    "        md_file.write(\"\\n\\n\")\n",
    "\n",
    "print(f\"✅ Exported merged markdown to {markdown_fname}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a5f767-2ca5-47c1-a62e-f6a4434475ae",
   "metadata": {},
   "source": [
    "### Create and save translation only markdown file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b84509-4139-44dc-ae0e-8d0c5021a9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Turn your existing JSON filename into a .md filename\n",
    "base = os.path.splitext(out_fname)[0]\n",
    "markdown_fname = base + '_translation_only' + '.md'\n",
    "\n",
    "# 2) Write each chunk’s original + final translation into the .md\n",
    "with open(markdown_fname, \"w\", encoding=\"utf-8\") as md_file:\n",
    "    for chunk in chunks:\n",
    "        md_file.write(chunk.get('final', ''))\n",
    "        md_file.write(\"\\n\\n\")\n",
    "\n",
    "print(f\"✅ Exported merged markdown to {markdown_fname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7dc26f-a4bd-4ea6-9063-90a62b898043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
